<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="CV/NLP，Studying，Coding">
<meta property="og:type" content="website">
<meta property="og:title" content="Deep Coding">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Deep Coding">
<meta property="og:description" content="CV/NLP，Studying，Coding">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Coding">
<meta name="twitter:description" content="CV/NLP，Studying，Coding">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>Deep Coding</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Deep Coding</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            日志
          </a>
        </li>
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/25/word2vec-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/25/word2vec-1/" itemprop="url">中文维基百科词向量Word2vec实战！</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T23:11:28+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/25/word2vec-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/01/25/word2vec-1/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>上一篇文章详细学习了Word2vec的含义及实现原理，包含两大语言模型：Cbow、Skip-Gram，以及两大快速训练技巧：Negative sampling、哈夫曼树形式查找Target word。这一篇主要讲基于中文维基百科语料库的Word2vec训练，采用了开源的python gensim包</p>
<h2 id="安装gensim包"><a href="#安装gensim包" class="headerlink" title="安装gensim包"></a>安装gensim包</h2><p>Google最初开源的Word2vec是用C++写的，后来陆续出现了很多版本，我们采用的是<a href="https://radimrehurek.com/gensim/models/word2vec.html" target="_blank" rel="noopener"><font color="blue"><strong>gensim</strong></font></a> ，gensim已经被集成在了conda中，所以我们可以方便地利用miniconda进行安装。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> activate py2k  <span class="comment"># 激活python2环境，当然python3也可以的，只不过笔者此处用的python2版本</span></span><br><span class="line">conda install gensim</span><br></pre></td></tr></table></figure></p>
<h2 id="获取维基百科语料库"><a href="#获取维基百科语料库" class="headerlink" title="获取维基百科语料库"></a>获取维基百科语料库</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>2017版百科语料下载地址为：<a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2。" target="_blank" rel="noopener">https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2。</a> 下载后是一个压缩包，里面的内容是从网上爬取的“标题–摘要–正文”对，以及其他的html、json标志符等。</p>
<h3 id="语料抽取"><a href="#语料抽取" class="headerlink" title="语料抽取"></a>语料抽取</h3><p><a href="https://github.com/attardi/wikiextractor" target="_blank" rel="noopener">Wikipedia Extractor</a>是一个开源的语料抽取工具，语料库压缩包不用在本地解压，直接用Wikipedia Extractor脚本执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/attardi/wikiextractor.git wikiextractor</span><br><span class="line">$ <span class="built_in">cd</span> wikiextractor</span><br><span class="line">$ sudo python setup.py install</span><br><span class="line">$ ./WikiExtractor.py -b 1024M -o extracted zhwiki-latest-pages-articles.xml.bz2 <span class="comment">#</span></span><br></pre></td></tr></table></figure></p>
<p>其中<code>2000M</code>代表抽取后的预料库最大允许size，因为原始语料库size约1.3G，这里用2000M的话相当于把语料全部抽取到一个文本文件“wiki_00”中。<code>extracted</code>代表抽取后语料存放路径。<br>最终控制台log输出：INFO: Finished 7-process extraction of 986891 articles in 1393.9s (708.0 art/s)，代表全部抽取完成共986891篇文章。<br>抽取后的内容格式为：每篇文章被一对<code>&lt;doc&gt;</code>、<code>&lt;/doc&gt;</code>包起来，而<code>&lt;doc&gt;</code>中的包含的属性有文章id、url和title属性，如<code>&lt;doc id=&quot;xxx&quot; url=&quot;https://zh.wikipedia.org/xxx&quot; title=&quot;xxx&quot;&gt;</code>。</p>
<h3 id="繁体字转简体"><a href="#繁体字转简体" class="headerlink" title="繁体字转简体"></a>繁体字转简体</h3><p>上一步抽取的中文维基百科语料库比较杂乱，既有繁体字也有简体字，这里需要将其统一变为简体字，采用开源的 <a href="https://github.com/BYVoid/OpenCC" target="_blank" rel="noopener">OpenCC</a>转换器。ubuntu下使用方法如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install opencc</span><br><span class="line">$ opencc -i wiki_00 -o zh_wiki_00 -c zht2zhs.ini</span><br></pre></td></tr></table></figure></p>
<h3 id="去除标点"><a href="#去除标点" class="headerlink" title="去除标点"></a>去除标点</h3><p>去除标点是因为：训练标点符号意义不大，且标点符号出现次数过多，影响一定训练效率。可以通过正则表达式去除。感谢<a href="http://wulc.me" target="_blank" rel="noopener">吴良超的学习笔记</a>提供的去标点程序，使用格式为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python script.py input_file output_file</span><br></pre></td></tr></table></figure></p>
<p>pre1.py源码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_process</span><span class="params">(input_file, output_file)</span>:</span></span><br><span class="line">    multi_version = re.compile(<span class="string">ur'-\&#123;.*?(zh-hans|zh-cn):([^;]*?)(;.*?)?\&#125;-'</span>)</span><br><span class="line">    punctuation = re.compile(<span class="string">u"[-~!@#$%^&amp;*()_+`=\[\]\\\&#123;\&#125;\"|;':,./&lt;&gt;?·！@#￥%……&amp;*（）——+【】、；‘：“”，。、《》？「『」』]"</span>)</span><br><span class="line">    <span class="keyword">with</span> io.open(output_file, mode = <span class="string">'w'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">        <span class="keyword">with</span> io.open(input_file, mode = <span class="string">'r'</span>, encoding =<span class="string">'utf-8'</span>) <span class="keyword">as</span> infile:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> infile:</span><br><span class="line">                line = multi_version.sub(<span class="string">ur'\2'</span>, line)</span><br><span class="line">                line = punctuation.sub(<span class="string">''</span>, line.decode(<span class="string">'utf8'</span>))</span><br><span class="line">                outfile.write(line)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) != <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Usage: python pre1.py input_file output_file"</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    input_file, output_file = sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>]</span><br><span class="line">    pre_process(input_file, output_file)</span><br></pre></td></tr></table></figure></p>
<h3 id="去除标识符及分词"><a href="#去除标识符及分词" class="headerlink" title="去除标识符及分词"></a>去除标识符及分词</h3><p>经过上一步处理，每一篇文章被存放在了<code>doc</code>/doc<code>标签。同时肉眼对比抽取后的句子，每一段落的开头跟标题都是重复的，也需要去除。还有前辈们建议把一篇段落的文章放到一行，但词向量关注的</code>window size`一般大小为3、5，感觉也没这个必要。安装<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">jieba分词</a>，pre2.py代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">jieba.load_userdict(<span class="string">"dict.txt"</span>) <span class="comment"># 如果有的话加载用户自定义词典</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_words</span><span class="params">(input_file, output_file)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    a = <span class="number">1</span> <span class="comment"># 标识符</span></span><br><span class="line">    <span class="keyword">with</span> io.open(output_file, mode = <span class="string">'w'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">        <span class="keyword">with</span> io.open(input_file, mode = <span class="string">'r'</span>, encoding = <span class="string">'utf-8'</span>) <span class="keyword">as</span> infile:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> infile:</span><br><span class="line">                <span class="keyword">if</span> a == <span class="number">-1</span>:</span><br><span class="line">                    a = a*(<span class="number">-1</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                line = line.strip() </span><br><span class="line">                <span class="keyword">if</span> len(line) &lt; <span class="number">1</span>: </span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># 移除字符串首尾的\r \n 空格等字符，此处希望一篇文章的所有内容位于一行，使得训练预料更规整</span></span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">'doc'</span>):</span><br><span class="line">                    <span class="keyword">if</span> line == <span class="string">'doc'</span>: </span><br><span class="line">                        outfile.write(<span class="string">u'\n'</span>) </span><br><span class="line">                        count += <span class="number">1</span></span><br><span class="line">                        str = <span class="string">"已完成 %d 篇百科文章转换"</span> % (count)</span><br><span class="line">                        <span class="keyword">print</span> str </span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        a = <span class="number">-1</span></span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">for</span> word <span class="keyword">in</span> jieba.cut(line):</span><br><span class="line">                        outfile.write(word + <span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Terminal Format: python script.py input_file output_file"</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    input_file, output_file = sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>]</span><br><span class="line">    cut_words(input_file, output_file)</span><br></pre></td></tr></table></figure></p>
<p>最终log输出：<code>已完成 986891 篇百科文章转换</code>，代表全部文章转换完毕。</p>
<h3 id="文本去重"><a href="#文本去重" class="headerlink" title="文本去重"></a>文本去重</h3><p>NLP常规操作，这么大的数据量，采用利用哈希表检测重复并去除，pre3.py代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*- </span></span><br><span class="line"><span class="comment">#程序功能是为了完成判断文件中是否有重复句子</span></span><br><span class="line"><span class="comment">#并将重复句子打印出来</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">res_list = set()</span><br><span class="line">f = open(<span class="string">'pre2'</span>,<span class="string">'r'</span>)</span><br><span class="line">w = open(<span class="string">'pre3'</span>, <span class="string">'w'</span>)</span><br><span class="line">k = <span class="number">1</span></span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">    index = index + <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> line <span class="keyword">in</span> res_list:</span><br><span class="line">        k = k + <span class="number">1</span></span><br><span class="line">        print(<span class="string">"Repeat"</span>, k, <span class="string">"All:"</span>, index, <span class="string">"Percent: %.5f%%"</span> % (<span class="number">100</span>*k/index))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        res_list.add(line)</span><br><span class="line">        w.write(line)</span><br></pre></td></tr></table></figure></p>
<p>最终log输出:<code>Repeat&#39;, 18649, &#39;All:&#39;, 986884, &#39;Percent: 1.00000%&#39;</code>，重复了1%的语料。</p>
<h2 id="用gensim训练词向量"><a href="#用gensim训练词向量" class="headerlink" title="用gensim训练词向量"></a>用gensim训练词向量</h2><h3 id="初始训练"><a href="#初始训练" class="headerlink" title="初始训练"></a>初始训练</h3><p>解释下参数含义：<br><code>multiprocessing</code>:python中的多线程模块，这里这里采用的是8核CPU进行训练，网络比较简单的情况下速度要比GPU快。<br><code>LineSentence</code>：将输入文件转为 gensim 内部的 LineSentence 对象，要求输入的文件的格式为<strong>每行一篇文章，对于中文每篇文章经过分词处理。</strong><br><code>min_count</code>：低于min_count的词频的词不参与训练；<code>sg</code>:0表示CBOW语言模型，1表示Skip-gram模型；<code>size</code>：词向量维度<br><code>iter</code>:迭代的epoch次数，这里着重讲下<strong>#此处的iter值会被直接设置到百分比进度条中，而不是日常训练神经网络一样epoch1、epoch2…epoch100</strong></p>
<p>train.py代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> gensim  </span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word2vec_train</span><span class="params">(input_file, output_file)</span>:</span></span><br><span class="line">    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</span><br><span class="line">    sentences = gensim.models.word2vec.LineSentence(input_file)</span><br><span class="line">    model = gensim.models.Word2Vec(sentences, size=<span class="number">800</span>, window=<span class="number">5</span>, min_count=<span class="number">3</span>, iter=<span class="number">100</span>,sg=<span class="number">0</span>, workers=multiprocessing.cpu_count())</span><br><span class="line">    <span class="comment"># model.train(sentences, total_examples=model.corpus_count, epochs = 100) 默认参数，也可以指定</span></span><br><span class="line">    model.save(output_file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Terminal Format: python script.py infile outfile"</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    input_file, output_file = sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>]</span><br><span class="line">    word2vec_train(input_file, output_file)</span><br></pre></td></tr></table></figure></p>
<p>最终log输出：<code>2018-01-22 19:37:52,179 : INFO : PROGRESS: at 100.00% examples, 122591 words/s, in_qsize 16, out_qsize 0</code><br>代表完成训练。</p>
<blockquote>
<ul>
<li>实验环境：ubuntu16.04、 CPU：8核</li>
</ul>
<ol>
<li>迭代5次epoch，耗时1.5小时</li>
<li>相同参数下，迭代100次epcoh，耗时40小时</li>
</ol>
</blockquote>
<h3 id="增量训练"><a href="#增量训练" class="headerlink" title="增量训练"></a>增量训练</h3><p>增量训练可以在新的语料库上，基于原有模型进行叠加训练，而不用从头开始。<br>train_add.py关键部分代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def word2vec_train(input_file, output_file):</span><br><span class="line">    logging.basicConfig(format=&apos;%(asctime)s : %(levelname)s : %(message)s&apos;, level=logging.INFO)</span><br><span class="line">    model = gensim.models.Word2Vec.load(&apos;word2vec&apos;)</span><br><span class="line">    more_sentences = gensim.models.word2vec.LineSentence(input_file)</span><br><span class="line">    model.build_vocab(more_sentences, update=True)</span><br><span class="line">    model.train(more_sentences, total_examples=model.corpus_count, epochs=model.iter)</span><br></pre></td></tr></table></figure></p>
<p>上面的代码先加载了一个已经训练好的词向量模型，然后再添加新的文章进行训练，同样新增的文章的格式也要满足每行一篇文章，每篇文章的词语通过空格分开的格式。由于前段时间参加Ai Challenge比赛，正好有1000W行处理后的中文数据可以加入训练。</p>
<h2 id="使用词向量模型"><a href="#使用词向量模型" class="headerlink" title="使用词向量模型"></a>使用词向量模型</h2><p>直接上代码了，infer.py如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line">model=gensim.models.Word2Vec.load(<span class="string">'word2vec'</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"模型加载成功！"</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"----词向量维度------"</span></span><br><span class="line"><span class="keyword">print</span> len(model[<span class="string">u'男人'</span>])</span><br><span class="line"><span class="keyword">print</span> <span class="string">"----跟“滋润”相近的词------"</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> model.most_similar(<span class="string">u"滋润"</span>):</span><br><span class="line">    <span class="keyword">print</span> i[<span class="number">0</span>],i[<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>Refer：<br><a href="http://blog.csdn.net/qq_32166627/article/details/68942216" target="_blank" rel="noopener">word2vec实战：获取和预处理中文维基百科(Wikipedia)语料库，并训练成word2vec模型</a><br><a href="http://wulc.me" target="_blank" rel="noopener">中文维基百科语料库词向量的训练</a><br><a href="http://kexue.fm/archives/4304/" target="_blank" rel="noopener">不可思议的Word2Vec</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/21/word2vec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/21/word2vec/" itemprop="url">Word2vec词向量原理解析！</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-21T15:46:11+08:00">
                2018-01-21
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/21/word2vec/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/01/21/word2vec/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-词汇表示Background"><a href="#1-词汇表示Background" class="headerlink" title="1. 词汇表示Background"></a>1. 词汇表示Background</h2><h3 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h3><p>文本、字符串看似简单，其实是经过几千万年的演化，人类抽象出的非常高维、稀疏的特征。拿汉语来说，词汇数量约为几十万。如果采用ont-hot形式编码，一个词语的维度就将占据几十万维。训练时候往往是上亿个词，这便会造成巨大的维数灾难。</p>
<h3 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h3><p>而<strong>Word2vec</strong>(中文名：词向量/词嵌入)，可以自由控制词汇的维度，常用的维度数一般为256、512…1024维。相对于one-hot编码词汇的离散表示，Word2vec是一种词汇的分布式表示(distribution representation)。比如某个词汇被以维度为[1,256]的一维向量表示，如果是一个包含100个词的句子，那么这句话被表示为[100,256]。写到这里，其实便可以意识到这跟图像用像素矩阵来表示是非常类似的。<br> <img src="/img/wpic2.jpeg" width="400" alt="图片名称" align="center"></p>
<h3 id="Word2vec特点"><a href="#Word2vec特点" class="headerlink" title="Word2vec特点"></a>Word2vec特点</h3><p>因为Deep learning的优势是从低维特征中自动学习、提取高维特征，词的分布式表示便可以充当词汇的低维特征表示，所以目前像文本分类、机器翻译、摘要等NLP任务，都使用Word2vec表示的词汇来作为模型的input。使得NLP领域也因为Deep learning 取得了不错的进步。如下是搜索“爱因斯坦”的相近词汇</p>
<pre><code class="bash">----跟“爱因斯坦”相近的词------
宇宙学 0.808888375759
牛顿 0.800362348557
相对论 0.791419327259
定律 0.76971578598
拓扑 0.764759659767
</code></pre>
<p>但因为Word2vec衡量的是文本共现程度，只能反映两者经常在相近的上下文环境中出现。所以它并不是真正意义上的语义表示，只能说一种近似，或者说其中存在很多的语义误差，并不像像素可以精确表示一副图像的底层信息。笔者认为这也是造成NLP领域并没有像图像、语音识别领域取得非常长足进步的重要原因。</p>
<blockquote>
<p>由于词汇背后丰富的语义信息，并不能通过Word2vec完全表示，最近也有学者尝试用更细的粒度来表示词汇。清华大学的刘知远老师利用HowNet：一种用最基本的、不宜再被分割的最小语义单位来表示的语义体系，跟Word2vec相结合，也获得了一些可以展望的成果<a href="https://www.zybuluo.com/cmd/" target="_blank" rel="noopener"><font color="#9999FF">《在深度学习时代用HowNet搞事情》</font></a></p>
</blockquote>
<hr>
<h3 id="Word2vec重要组件"><a href="#Word2vec重要组件" class="headerlink" title="Word2vec重要组件"></a>Word2vec重要组件</h3><p>Word2vec(以下简称词向量)，虽然作为概率语言模型的input，但其实是训练语言模型产生的中间结果。</p>
<blockquote>
<ul>
<li><strong>两个语言模型：</strong><ul>
<li>Skip-gram：根据当前词语w<sub>t</sub>，预测上下文的词语(w<sub>t-1</sub>、w<sub>t+1</sub>)的模型。</li>
<li>CBOW：Continuous Bag-of-Words Model的缩写，与Skip-gram正好相反</li>
</ul>
</li>
<li><strong>优化Softmax归一化：</strong><ul>
<li>Hierarchical Softmax：采用哈夫曼树思想分层求取Target概率</li>
<li>Negative sampling：softmax时仅采样少量词汇作映射</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h2 id="2-Word2vec重要组件详解"><a href="#2-Word2vec重要组件详解" class="headerlink" title="2. Word2vec重要组件详解"></a>2. Word2vec重要组件详解</h2><h3 id="神经网络语言模型简化"><a href="#神经网络语言模型简化" class="headerlink" title="神经网络语言模型简化"></a>神经网络语言模型简化</h3><p>简化后训练Language model的神经网络如图所示，甚至都没有Hidden Layer层，是一个直接从input到output的映射。<br> <img src="/img/wpic5.jpeg" width="400" alt="图片名称" align="center"><br>图中的三层含义：</p>
<blockquote>
<p>input：上下文的词向量(注意我们训练的是CBOW语言模型，词向量只是模型的一个参数，起始时是个随机值)<br>  projection：上下文词向量simply add(若是Skip-gram为input本身)<br>  output：按理说此处应当是在词表维度C上的概率分布</p>
</blockquote>
<p>参数化表示上面的CBOW语言模型后，如下图所示：(看这里更清楚了，这不就是纯粹的softmax公式么…)<br> <img src="/img/wpic7.jpeg" width="350" alt="图片名称" align="center"><br>简单计算下这个网络从projection Layer到Output Layer 全连接网络层之间的参数：projection Layer即词向量维度在10<sup>2</sup>量级；词表(Vocab)数量在10<sup>5</sup>量级；语料库中需要训练的词汇数量一般在10<sup>7</sup>量级以上。这样的运算次数是十分吓人的！</p>
<h3 id="Hierarchical-Softmax"><a href="#Hierarchical-Softmax" class="headerlink" title="Hierarchical Softmax"></a>Hierarchical Softmax</h3><p><strong><code>重点：</code></strong>作者此处便采用了哈夫曼树的思想：具体做法是将语料库中的词按先词频排序，然后不断合并最小的两个节点成为一棵哈夫曼树，最终合并效果如下所示，词表中的所有词汇均为于树的叶节点上(详见：<a href="http://www.icourse163.org/learn/ZJU-93001?tid=1002019005#/learn/content?type=detail&amp;id=1002635018&amp;cid=1002891113" target="_blank" rel="noopener"><font color="blue">10分钟便能懂的公开课</font></a>)<br> <img src="/img/wpic8.jpeg" width="450" alt="图片名称" align="center"><br><strong>生成Target词汇的概率为从跟节点到叶子节点路径的概率连乘</strong>(见下图)。而哈夫曼树相比于其他形式的二叉树，将高频词赋予更短的编码，可以进一步减少概率P相乘次数。下面用图解的方式说明为什么采用哈夫曼树可以加快计算速度。</p>
<blockquote>
<p>极限假设词向量维度为3，词表大小为20。那么全连接网络1次迭代需要训练的参数数量为60个，接着再进行softmax归一化。<br>哈夫曼树的形式，假设目标词汇是图中的节点8，根结点到8节点一共经过5个节点(哈夫曼树编码知识，8节点的编码表示为:11110，那么计算Target词汇概率，仅涉及3*5=15个参数的计算。</p>
</blockquote>
<p><img src="/img/wpic9.jpeg" width="450" alt="图片名称" align="center"><br>基于二叉树的这种性质，计算复杂度从之前的O(N)变为O(logN)，运算速度指数级提升。<br>而<strong>Cost函数为对概率连乘取log对数</strong>，如下：<br> <img src="/img/wpic12.jpeg" width="250" alt="图片名称" align="center"><br> <img src="/img/wpic13.jpeg" width="250" alt="图片名称" align="center"></p>
<p>训练目标是最大化Cost函数，采用的算法是梯度上升。其实跟梯度下降非常类似，cost对参数向量取偏导数得到梯度，参数更新时候再加上该梯度乘learning rate就可以了，不过此处涉及两个参数向量，一个是权重theta，另一个就是词向量。此处直接复制Hankcs.com中的推导结果，两个参数更新方式如下：<br> <img src="/img/wpic10.jpeg" width="300" alt="图片名称" align="center"><br> <img src="/img/wpic11.jpeg" width="300" alt="图片名称" align="center"><br>如此便完成了一次完整的训练周期！<br> <font color="red"><strong>更简单直白的总结是：扁平的softmax在计算P(y=j)，需要计算整个词表每个词的概率，而现在分层的softmax只需要计算一条路径上节点的概率值，便可以得到P(y=j)，接着进行梯度上升，不断使概率P变大</strong></font></p>
<hr>
<h3 id="Negative-sampling"><a href="#Negative-sampling" class="headerlink" title="Negative sampling"></a>Negative sampling</h3><h4 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h4><p>由于Hierarchical Softmax对于频率较低的词汇，依然需要花费较长的步骤才能找到该词。所以作者引入了另一种算法：<strong>Negative sampling</strong>(sampled softmax)，即：为了加快训练速度，在loss计算时，采用负采样方式，并不是求整个vocab的softmax概率，而是随机采样的W个。这样每次训练中就可以更新这少量的W个参数，其他参数被冻结(需要注意总的参数数量不变，只是每次参与迭代计算的数量锐减)。<br><strong><code>需要注意：</code></strong>在Test阶段，要到整个词表中softmax(此时词向量本身及其权重已经被计算了出来)，来确定下一次选中的是哪些词汇(可接beam search)。若是哈夫曼树，Test时会找出一个确定的词<br>我们原来模型每次运行，假设词向量维度：300；vocab大小：1W，之前每次迭代需要跟新300W参数。现在负采样个数N=5。只要跟新300×(1+5)=1800，参数减少了非常多，训练速度大幅加快。</p>
<h4 id="采样方法："><a href="#采样方法：" class="headerlink" title="采样方法："></a>采样方法：</h4><p>那怎样确定负采样个数N呢？其实就是随机抽取，但要考虑词频的影响，词频越高，越容易被抽出来。具体到word2vec中，作者是这样实现的：采用一个大小为M的table(M&gt;&gt;vocab size，一般取10^8)。分为M份，每份代表一个词，如图所示；<br> <img src="/img/wpic14.jpeg" width="450" alt="图片名称" align="center"><br>但具体怎么确定哪一份对应什么词呢？作者采用了如下的公示计算每个词的份额(对应在tabel上占据的长度)<br> <img src="/img/wpic15.jpeg" width="270" alt="图片名称" align="center"><br>在paper中提到0.75这个超参是试出来的，实现的话就是直接1～M取一个随机数，从中提取对应的项便可以了。</p>
<hr>
<h2 id="Ref："><a href="#Ref：" class="headerlink" title="Ref："></a>Ref：</h2><p><a href="http://www.hankcs.com/nlp/word2vec.html" target="_blank" rel="noopener"><font color="#9999FF">Blog：Word2vec原理推导与代码分析</font></a><br><a href="https://www.zybuluo.com/Dounm/note/591752#71-paragraph2vec" target="_blank" rel="noopener"><font color="#9999FF">Blog：Word2vec-知其然知其所以然</font></a><br><a href="http://wulc.me/" target="_blank" rel="noopener"><font color="#9999FF">Blog：中文维基百科语料库词向量的训练</font></a><br><a href="http://blog.csdn.net/layumi1993/article/details/72868399#t1" target="_blank" rel="noopener"><font color="#9999FF">Blog：Word2vec教程-Negative Sampling</font></a><br>《word2vec中的数学原理详解》<br>《Tensorflow实战》</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/17/tmux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/17/tmux/" itemprop="url">tmux——轻松实现进程后台托管!</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-17T23:04:15+08:00">
                2018-01-17
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/17/tmux/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/01/17/tmux/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h4><p>远程连接服务器跑模型时，经常由于客户端IP地址发生变化，或者关闭Terminal窗口，而导致服务器Session终端，这里介绍一种<strong>可随时从Session中抽离，又能在需要时候重新回到该Session的方法</strong></p>
<p><font color="blue"> 以下程序均为在服务器端操作，或者SSH远程服务器操作 </font></p>
<h5 id="1、服务器端安装tmux"><a href="#1、服务器端安装tmux" class="headerlink" title="1、服务器端安装tmux"></a>1、服务器端安装tmux</h5><pre><code class="bash">$ apt-get install tmux
</code></pre>
<h5 id="2、Terminal窗口直接键入tmux，进入一个session，左下角显示该session进程号"><a href="#2、Terminal窗口直接键入tmux，进入一个session，左下角显示该session进程号" class="headerlink" title="2、Terminal窗口直接键入tmux，进入一个session，左下角显示该session进程号"></a>2、Terminal窗口直接键入tmux，进入一个session，左下角显示该session进程号</h5><pre><code class="bash">$ tmux
</code></pre>
<p>现在便可随时关闭Terminal，Session便可以在后台安静稳定地运行！需要恢复该Session时：</p>
<pre><code class="bash">$ tmux attach -t 0
</code></pre>
<h5 id="3、杀掉该session"><a href="#3、杀掉该session" class="headerlink" title="3、杀掉该session"></a>3、杀掉该session</h5><p>在某个tmux窗口内，输入exit便可以kill并退出</p>
<pre><code class="bash">$ <span class="built_in">exit</span>
</code></pre>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/16/Conda-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/16/Conda-md/" itemprop="url">Conda切换python2/3环境！🐶</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-16T15:52:19+08:00">
                2018-01-16
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/16/Conda-md/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/01/16/Conda-md/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>Python的全局锁有时候非常烦。很多人电脑里都会同时装python2、python3。但在linux安装各种包时，长期混乱地pip、pip3随便安装，时间久了便造成安装环境混乱，导致<font color="blue">“明明安装了某种包，在使用时却未发现该包的错误” </font></p>
<p>在这里介绍一种牛逼的包管理工具Miniconda，以明确规定python环境，再安装相应python版本的包，再安全使用该包。博主被Tensorflow的各种版本及依赖库苦扰了好久，不要贪图省事儿，一次彻底搞定，后面才可以节节高！</p>
<h5 id="Minicoda安装："><a href="#Minicoda安装：" class="headerlink" title="Minicoda安装："></a>Minicoda安装：</h5><p>Welcome to <a href="https://conda.io/miniconda.html" target="_blank" rel="noopener">Miniconda</a>! 点击链接，下载对应操作系统的Miniconda即可！<br><img src="/img/conda.jpeg" alt=""><br><strong>Tips：</strong>安装miniconda时不要以root权限安装，同时安装过程最好选择默认选项，最后在Linux的用户目录下创建一个叫miniconda的文件夹。这样的好处，同一台主机的不同用户可以安装自己的anaconda，配置自己的Python环境，大家不相互影响。</p>
<h5 id="将conda添加到系统环境变量"><a href="#将conda添加到系统环境变量" class="headerlink" title="将conda添加到系统环境变量"></a>将conda添加到系统环境变量</h5><pre><code class="bash">$ vi ~/.bashrc
在最后添加一项：<span class="built_in">export</span> PATH=<span class="string">"<span class="variable">$PATH</span>:~/miniconda3/bin"</span> 
此处<span class="variable">$PATH</span>在miniconda3路径之前，默认先调用系统中安装的python
$ <span class="built_in">source</span> ~/.bashrc
</code></pre>
<h5 id="conda创建python2环境"><a href="#conda创建python2环境" class="headerlink" title="conda创建python2环境"></a>conda创建python2环境</h5><pre><code class="bash">$ conda create -n py2k python=2.7
</code></pre>
<h5 id="同时安装必要的包"><a href="#同时安装必要的包" class="headerlink" title="同时安装必要的包"></a>同时安装必要的包</h5><p>Tips:通过conda某个环境安装的包都在…/miniconda/envs/py2k/lib/python2.7/site-packages/xxx，需要时候可以查阅各个包的源码</p>
<pre><code class="bash">$ conda create -n py2k numpy
</code></pre>
<h5 id="切换到新环境（-linux-Mac下）"><a href="#切换到新环境（-linux-Mac下）" class="headerlink" title="切换到新环境（ linux/Mac下）"></a>切换到新环境（ linux/Mac下）</h5><pre><code class="bash">$ <span class="built_in">source</span> activate py2k
</code></pre>
<p><font color="red"> 比如说需要安装py2版本的Tensorflow及github上其他的一些包，均需要在安装、使用时先切换到该环境下 </font></p>
<h5 id="退出环境"><a href="#退出环境" class="headerlink" title="退出环境"></a>退出环境</h5><pre><code class="bash">$ deactivate py2k
</code></pre>
<h5 id="移除环境"><a href="#移除环境" class="headerlink" title="移除环境"></a>移除环境</h5><pre><code class="bash">$ conda remove -n py2k --all
</code></pre>
<h5 id="查看当前所有环境"><a href="#查看当前所有环境" class="headerlink" title="查看当前所有环境"></a>查看当前所有环境</h5><pre><code class="bash">$ conda info -e (带*的就是当前默认环境)
</code></pre>
<h5 id="指定查看某环境下安装的package"><a href="#指定查看某环境下安装的package" class="headerlink" title="指定查看某环境下安装的package"></a>指定查看某环境下安装的package</h5><pre><code class="bash">$ conda list -n env_name
</code></pre>
<h5 id="查找是否有某个包可被安装"><a href="#查找是否有某个包可被安装" class="headerlink" title="查找是否有某个包可被安装"></a>查找是否有某个包可被安装</h5><pre><code class="bash">$ conda search pyqtgraph
</code></pre>
<h5 id="有些包在国外，需要搭梯子，这里推荐清华大学的开源工具包，下载速度飞快！！"><a href="#有些包在国外，需要搭梯子，这里推荐清华大学的开源工具包，下载速度飞快！！" class="headerlink" title="有些包在国外，需要搭梯子，这里推荐清华大学的开源工具包，下载速度飞快！！"></a>有些包在国外，需要搭梯子，这里推荐清华大学的开源工具包，下载速度飞快！！</h5><p>Ps：仅需配置一次，配置文件位于<code>/home/tucodec/.condarc</code></p>
<pre><code class="bash">$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
$ conda config --<span class="built_in">set</span> show_channel_urls yes
</code></pre>
<p>最后看看Miniconda管理的成果吧！<br><img src="/img/conda_1.jpeg" alt=""></p>
<h5 id="conda与系统环境相关事宜"><a href="#conda与系统环境相关事宜" class="headerlink" title="conda与系统环境相关事宜"></a>conda与系统环境相关事宜</h5><p>1、Terminal窗口下，直接<code>pip install xxx</code>，会默认安装到系统的~/python/sitepackage目录中；conda的python环境下，才会安装到对应~/miniconda/python/sitepackage目录中。<br>2、直接在Terminal窗口输入python2/3，会优先搜索安装在系统路径的python，如果没有对应的python版本，才会调用miniconda中的python。<br>3、假如在系统路径直接pip install gensim，那么在miniconda的python环境下是调不到的，所以最好是先source activate python环境，再pip/conda安装相应的软件 </p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/14/Knowledge/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/14/Knowledge/" itemprop="url">知识图谱私见！🐶</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-14T12:52:19+08:00">
                2018-01-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/14/Knowledge/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/01/14/Knowledge/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h3><p>2012年5月，Google推出Google知识图谱（GoogleKnowledge Graph），并利用其在搜索引擎中增强搜索结果。这是“知识图谱”名称的由来，也标志着大规模知识图谱在互联网语义搜索中的成功应用。</p>
<p>Eg：搜索“吴彦祖的国籍是什么？”，Google/Baidu会给出与之相关的详细搜索结果（可以叫“搜索++”或者“搜索杂烩且精准”，顺带提一句，搜索本身就是AI，没必要将其神秘化，之前到现在一只都有，只是如同其他任何一个行业，发展的越来越好，2012年后随着深度学习的爆发，迎来了一波小高潮）</p>
<p><img src="/img/wuyanzu.jpeg" alt=""></p>
<h4 id="知识图谱概念"><a href="#知识图谱概念" class="headerlink" title="知识图谱概念"></a>知识图谱概念</h4><p><strong>定义：</strong>知识图谱旨在描述真实世界中存在的各种实体或概念及其关系，其构成一张巨大的语义网络图，节点表示实体或概念，边则由属性或关系构成。</p>
<p><strong>节点：</strong>知识图谱包括<code>实体</code>、<code>属性/语义类</code>、<code>属性值</code>、<code>关系</code>这么4种节点。最终以三元组的形式呈现，主要包括(实体1-关系-实体2)和(实体-属性-属性值)等。</p>
<blockquote>
<p>中国-首都-北京是一个（实体-关系-实体）的三元组样例.<br>北京-人口-2069.3万是一个（实体-属性-属性值）的三元组样例。</p>
</blockquote>
<h4 id="构建："><a href="#构建：" class="headerlink" title="构建："></a>构建：</h4><p>知识图谱的构建技术包括3大方面：知识提取、知识表示、知识融合。后两方面自己目前的知识面尚未覆盖，仅就Deep Learning相关的来说，<br>知识提取部分又包括<strong>实体抽取、语义类抽取、属性和属性值抽取</strong>。</p>
<blockquote>
<p>实体抽取目前有用<code>BiLstm+CRF</code>算法来做；<br>语义类抽取笔者自己也尝试了用word2vec进行相似度匹配，效果还不错；<br>属性和属性值抽取，笔者尝试了用命名实体识别工具+正则匹配的方式也能完成一定程度的，像地名、场景、日期、车牌等信息的抽取。</p>
</blockquote>
<p>目前工业界基本也是通过从半结构化的数据中抽取信息，而不是通过<strong>“阅读”</strong>句子产生真正的理解来抽取，深层自然语言处理这块儿骨头太硬了。</p>
<h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><p>写到这里，笔者更认为深度学习也是构建知识图谱的一种方式，深度学习能较好解决机器翻译、客服对话等小任务，也是一定程度上对知识地综合理解，比如通过机器翻译，建立英语、中文之间的联系，通过Imagenet图像分类，建立1000种Object的对应关系。但，深度学习在NLP/图像中对“语义”的理解，还是太过单薄，设计太过简陋，面对这些非结构化的大量知识体系，无从下口、束手无策。</p>
<blockquote>
<p>能够将知识图谱的各条“边”剥离清楚的，深度学习还需要再向前推进一大步，远不止目前的CNN、RNN…<br>而知识图谱本身的发展，应该要求更高，需要的是更加综合的知识。</p>
</blockquote>
<h5 id="——不能真正创造价值的概念，都是耍流氓！"><a href="#——不能真正创造价值的概念，都是耍流氓！" class="headerlink" title=" ——不能真正创造价值的概念，都是耍流氓！"></a><font color="red"> ——不能真正创造价值的概念，都是耍流氓！</font></h5><p>话说回来吧，借助某位哲人说的，希望自己摒弃热潮，以工程任务为导向。首要解决当下NLP能解决的任务，这也是本博客名称“Deep coding”的由来。</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/06/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/06/hello-world/" itemprop="url">Hexo搭建Step by step！ 👏👏👏</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-06T16:08:28+08:00">
                2018-01-06
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/01/06/hello-world/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/01/06/hello-world/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="A、Quick-Start"><a href="#A、Quick-Start" class="headerlink" title="A、Quick Start"></a>A、Quick Start</h4><h5 id="Node-js官网下载对应的安装包："><a href="#Node-js官网下载对应的安装包：" class="headerlink" title="Node.js官网下载对应的安装包："></a>Node.js官网下载对应的安装包：</h5><p><font color="blue"> [Download] </font> (<a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a>)</p>
<h5 id="安装Git：Mac用Brew安装，其他方法网上一大堆不再赘述"><a href="#安装Git：Mac用Brew安装，其他方法网上一大堆不再赘述" class="headerlink" title="安装Git：Mac用Brew安装，其他方法网上一大堆不再赘述"></a>安装Git：Mac用Brew安装，其他方法网上一大堆不再赘述</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install git</span><br></pre></td></tr></table></figure>
<h5 id="Node和Git都安装好后，可执行如下命令安装hexo："><a href="#Node和Git都安装好后，可执行如下命令安装hexo：" class="headerlink" title="Node和Git都安装好后，可执行如下命令安装hexo："></a>Node和Git都安装好后，可执行如下命令安装hexo：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo npm install -g hexo</span><br></pre></td></tr></table></figure>
<h5 id="Desktop-或其它文件夹-中新建一个Blog文件夹，cd到新创建的Blog："><a href="#Desktop-或其它文件夹-中新建一个Blog文件夹，cd到新创建的Blog：" class="headerlink" title="Desktop(或其它文件夹)中新建一个Blog文件夹，cd到新创建的Blog："></a>Desktop(或其它文件夹)中新建一个Blog文件夹，cd到新创建的Blog：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init</span><br></pre></td></tr></table></figure>
<h5 id="至此：全部安装工作已经完成！生成静态页面："><a href="#至此：全部安装工作已经完成！生成静态页面：" class="headerlink" title="至此：全部安装工作已经完成！生成静态页面："></a>至此：全部安装工作已经完成！生成静态页面：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo g</span><br></pre></td></tr></table></figure>
<h5 id="启动本地服务："><a href="#启动本地服务：" class="headerlink" title="启动本地服务："></a>启动本地服务：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<h5 id="此时浏览器输入-http-localhost-4000-即可访问原生默认网页"><a href="#此时浏览器输入-http-localhost-4000-即可访问原生默认网页" class="headerlink" title="此时浏览器输入 http://localhost:4000 即可访问原生默认网页"></a>此时浏览器输入 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 即可访问原生默认网页</h5><h4 id="B、主题下载"><a href="#B、主题下载" class="headerlink" title="B、主题下载"></a>B、主题下载</h4><p>此时如果想尝鲜，可以下载个新的主题到themes文件夹下，笔者用的主题是<a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">Download</a></p>
<p>修改根目录中_config.yml文件的theme项为新下载的主题的名字：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: hexo-theme-next-master</span><br></pre></td></tr></table></figure>
<p>保存文件后，执行下面的指令，重新打开浏览器即可看到新的一片天地</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo g    hexo server</span><br></pre></td></tr></table></figure>
<h4 id="C、绑定Github，实现远程访问"><a href="#C、绑定Github，实现远程访问" class="headerlink" title="C、绑定Github，实现远程访问"></a>C、绑定Github，实现远程访问</h4><h5 id="Github上建立一个与用户名【相同】的Repository"><a href="#Github上建立一个与用户名【相同】的Repository" class="headerlink" title="Github上建立一个与用户名【相同】的Repository"></a>Github上建立一个与用户名【相同】的Repository</h5><h5 id="在建立的Repository-Setting中，最后一项Deploy添加SSH-key"><a href="#在建立的Repository-Setting中，最后一项Deploy添加SSH-key" class="headerlink" title="在建立的Repository Setting中，最后一项Deploy添加SSH key"></a>在建立的Repository Setting中，最后一项Deploy添加SSH key</h5><p>获取SSH key的方式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C “wuxj231@163.com” <span class="comment"># 这里填写你的Github地址</span></span><br></pre></td></tr></table></figure>
<p>一路回车Ctrl，生成两个文件，用记事本打开其中的id_rsa.pub(执行上面Shell语句时会提示路径所在)，复制其内容，粘贴到上一步Github/Repository Setting页面中的key目录中，Title随便取即可</p>
<p><img src="/img/ssh.jpeg" alt=""></p>
<h5 id="编辑-config-yml，翻到最下面，修改相应内容如下："><a href="#编辑-config-yml，翻到最下面，修改相应内容如下：" class="headerlink" title="编辑 _config.yml，翻到最下面，修改相应内容如下："></a>编辑 _config.yml，翻到最下面，修改相应内容如下：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: git@github.com:Wxjwjj/Wxjwjj.github.io.git  </span><br><span class="line">  branch: master</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment">##### 保存后，执行如下命令使用git部署，便会同步到Github目录</span></span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">$ npm install hexo-deployer-git --save</span><br><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>此时可以通过Github链接 <em><a href="https://wxjwjj.github.io" target="_blank" rel="noopener">https://wxjwjj.github.io</a></em> ，实现远程博客访问（如果本地文件更改后，均需要通过此步骤提交到Github，才能使变化生效）</p>
<h5 id="Refer："><a href="#Refer：" class="headerlink" title="Refer："></a>Refer：</h5><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](<a href="https://hexo.io/docs/" target="_blank" rel="noopener">https://hexo.io/docs/</a></p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg"
                alt="祥吉" />
            
              <p class="site-author-name" itemprop="name">祥吉</p>
              <p class="site-description motion-element" itemprop="description">CV/NLP，Studying，Coding</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">36</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:wuxj231@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/xj-wu-74/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-rocket"></i>知乎</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/5379129372/home?wvr=5&lf=reg" target="_blank" title="微博">
                      
                        <i class="fa fa-fw fa-weibo"></i>微博</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">祥吉</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>


              
 
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共30.1k字</span>
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  


















  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  
</body>
</html>
