<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="NLP/CV，Studying，Coding">
<meta property="og:type" content="website">
<meta property="og:title" content="Deep Coding">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Deep Coding">
<meta property="og:description" content="NLP/CV，Studying，Coding">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Coding">
<meta name="twitter:description" content="NLP/CV，Studying，Coding">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Deep Coding</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Deep Coding</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            日志
          </a>
        </li>
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/29/Seetaface-linux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/29/Seetaface-linux/" itemprop="url">Seetaface 人脸识别 for Linux/Mac</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-29T14:33:12+08:00">
                2018-03-29
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/29/Seetaface-linux/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/29/Seetaface-linux/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近做人脸检测的项目，需要用到中科院山世光老师团队开源的SeetaFace，在Ubuntu、Mac端分别进行了编译，系统信息如下：</p>
<blockquote>
<p>Ubuntu:16.04     opencv:3.1.0    cmake:3.5.1<br>MacOS:10.13        opencv:3.4.3    cmake:3.0.2</p>
</blockquote>
<h4 id="FaceDetection-模块"><a href="#FaceDetection-模块" class="headerlink" title="FaceDetection 模块"></a>FaceDetection 模块</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/&lt;user name&gt;/SeetaFaceEngine/FaceDetection</span><br><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make -j8</span><br></pre></td></tr></table></figure>
<p>不出意外即可在build目录下生成可执行文件<code>facedet_test</code>，调用方式<code>./facedet_test image_path ../model/seeta_fd_frontal_v1.0.bin</code>，结果如图示<br><img src="/img/seeta1.jpeg" width="400" alt="图片名称" align="center"><br><strong>PS:</strong><br>1、编译阶段若提示opencv版本问题<br>ccmake .. 修改其中OpenCV_DIR路径为自己的opencv安装目录，configuration使之生效<br>Eg：OpenCV_DIR /home/<user name="">/opencv-3.1.0/build<br>接着设置CUDA_USE_STATIC_CUDA_RUNTIME OFF<br>重新<code>cmake ..</code>，不报错再继续<code>make</code>。</user></p>
<h4 id="FaceAlignment-模块"><a href="#FaceAlignment-模块" class="headerlink" title="FaceAlignment 模块"></a>FaceAlignment 模块</h4><p>该模块依赖FaceDetection，先检测图像中哪个区域存在人脸，之后进行关键点检测，所以先复制FaceDetection模块中的相关头文件、依赖、模型到FaceAlignment/build目录中，具体如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/&lt;user name&gt;/SeetaFaceEngine/FaceAlignment</span><br><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cp ../../FaceDetection/include/face_detection.h ../include</span><br><span class="line">cp ../../FaceDetection/build/libseeta_facedet_lib.so ./</span><br><span class="line">cp ../../FaceDetection/model/seeta_fd_frontal_v1.0.bin ./</span><br></pre></td></tr></table></figure></p>
<p>接着修改<code>face_alignment_test.cpp</code>中，FaceDetection model路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Initialize face detection model</span><br><span class="line">seeta::FaceDetection detector(&quot;./build/seeta_fd_frontal_v1.0.bin&quot;);</span><br></pre></td></tr></table></figure></p>
<p>接着编译<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake ..</span><br><span class="line">make -j8</span><br></pre></td></tr></table></figure></p>
<p>之后运行下<code>./build/fa_test</code>，生成如图示的关键点检测图片(注意.cpp文件中定义了仅能检测一张人脸)<br><img src="/img/seeta2.jpeg" width="400" alt="图片名称" align="center"><br><strong>PS:</strong><br>1、编译阶段若提示‘isnan’ was not declared in this scope，定位到源文件，修改为<code>std::isnan</code>便可以了。<br>2、运行阶段提示Segmentation fault (core dumped)，应该是模型或图片路径不对，对于Linux或mac，cpp文件中指定的路径应当是相对于<code>CMakelists.txt</code>的路径</p>
<h4 id="FaceIdentification-模块"><a href="#FaceIdentification-模块" class="headerlink" title="FaceIdentification 模块"></a>FaceIdentification 模块</h4><p>类似的步骤如上，把FaceDetection、FaceAlignment模块的相关依赖拷贝进入build文件夹。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/&lt;user name&gt;/SeetaFaceEngine/FaceAlignment</span><br><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cp ../../FaceDetection/include/face_detection.h ../include</span><br><span class="line">cp ../../FaceDetection/build/libseeta_facedet_lib.so ./</span><br><span class="line">cp ../../FaceDetection/model/seeta_fd_frontal_v1.0.bin ./</span><br><span class="line">cp ../../FaceAlignment/include/face_alignment.h ../include</span><br><span class="line">cp ../../FaceAlignment/build/libseeta_fa_lib.so ./</span><br><span class="line">cp ../../FaceAlignment/model/seeta_fa_v1.1.bin ./</span><br></pre></td></tr></table></figure></p>
<p>解压FaceIdentification/model中的两个文件(解压part1，会自动将part2解压)，同样修改<code>./src/test</code>目录的两个CPP文件中，前两个model的路径，同上。<br>&nbsp;<br>再修改<code>/test</code>下的两个cpp文件，加上<code>opencv2</code>头文件，注意这里头文件顺序需要放在<code>cvLIB</code>宏定义之后，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line">#include &lt;opencv2/highgui/highgui.hpp&gt;</span><br><span class="line">#include &lt;opencv2/imgproc/imgproc.hpp&gt;</span><br></pre></td></tr></table></figure></p>
<p>接着编译<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake ..</span><br><span class="line">make -j8</span><br></pre></td></tr></table></figure></p>
<p>之后运行<code>./build/src/test/test_face_recognizer.bin</code>，测试3个模块。<code>./build/src/test/test_face_verification.bin</code>测试存取的样本中图片的相似度即可。<br><strong>PS:</strong><br>1、编译到99%时报错，提示没有相关的库，需要改写/src/test中的Cmakelists.txt，在其中添加Detect、Align模块的lib库（也就是在当前build文件夹下查找），如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">aux_source_directory (. SRC_LIST)</span><br><span class="line">link_directories(<span class="variable">$&#123;PROJECT_BINARY_DIR&#125;</span>) <span class="comment"># 添加lib库搜索路径</span></span><br><span class="line">message(<span class="variable">$&#123;SRC_LIST&#125;</span>)</span><br><span class="line"><span class="comment"># add external libraries</span></span><br><span class="line">find_package(OpenCV REQUIRED)</span><br><span class="line">include_directories(<span class="variable">$&#123;seeta_facedet_lib_INCLUDE_DIRS&#125;</span> <span class="variable">$&#123;seeta_fa_lib_INCLUDE_DIRS&#125;</span>)</span><br><span class="line">list(APPEND seeta_fi_lib_required_libs <span class="variable">$&#123;OpenCV_LIBS&#125;</span> seeta_facedet_lib seeta_fa_lib)</span><br><span class="line">enable_testing ()</span><br><span class="line">foreach (f <span class="variable">$&#123;SRC_LIST&#125;</span>)</span><br><span class="line">  string(REGEX REPLACE <span class="string">"[.]cpp"</span> <span class="string">".bin"</span> BIN <span class="variable">$&#123;f&#125;</span>)</span><br><span class="line">  add_executable(<span class="variable">$&#123;BIN&#125;</span> <span class="variable">$&#123;f&#125;</span>)</span><br><span class="line">  <span class="comment">#target_link_libraries($&#123;BIN&#125; viplnet $&#123;OpenCV_LIBS&#125; seeta_facede_lib seeta_fa_lib)</span></span><br><span class="line">  target_link_libraries(<span class="variable">$&#123;BIN&#125;</span> viplnet <span class="variable">$&#123;seeta_fi_lib_required_libs&#125;</span>) <span class="comment"># 添加lib</span></span><br><span class="line">endforeach ()</span><br></pre></td></tr></table></figure></p>
<h4 id="Mac编译"><a href="#Mac编译" class="headerlink" title="Mac编译"></a>Mac编译</h4><p>与Linux相比，Mac的就非常简单了，需要注意Detection模块中，CMakelists.txt要求的cmake为3.1及以上，笔者是3.0，所以在这里对CMakelists.txt做简单修改，如果是Brew安装的opencv，那其他的<code>ccmake</code>配置也不用修改<br>&nbsp;<br>之后的操作步骤与Linux描述的基本一致，编译过程中可能会有很多warning，不用管，直接<code>make</code>即可。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/27/ubuntusys-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/27/ubuntusys-1/" itemprop="url">Ubuntu1604装机系列(三)：Matlab2017b安装</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-27T11:08:34+08:00">
                2018-03-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/27/ubuntusys-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/27/ubuntusys-1/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><p>Matlab下载<a href="https://pan.baidu.com/s/14U8J9YYP6OSEhCqR1ls-Wg" target="_blank" rel="noopener">链接</a> 密码: ckw4<br>解压后得到<code>xxx_dvd1.iso</code>、<code>xxx_dvd2.iso</code>、<code>crack</code>破解文件</p>
<h4 id="挂载镜像文件dvd1"><a href="#挂载镜像文件dvd1" class="headerlink" title="挂载镜像文件dvd1"></a>挂载镜像文件dvd1</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /home/&lt;user name&gt;/Matlab </span><br><span class="line">sudo mount -t auto -o loop /home/&lt;user name&gt;/xxx_dvd1.iso /home/&lt;user name&gt;/Matlab</span><br></pre></td></tr></table></figure>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> </span><br><span class="line">sudo ./Matlab/install</span><br></pre></td></tr></table></figure>
<h4 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h4><p>在弹出的安装对话框中，选择离线安装，并填入<code>license number</code>，复制crack解压后出现的readme.txt文件中的第一个安装密钥即可<br>&nbsp;<br>安装路径默认是系统目录，改为<code>/home/&lt;user name&gt;/matlab/r2017b</code>，这样的好处是遵循了Linux处处是文件的思想，方便每个用户的版本管理，同时若安装失败直接删除该<code>/matlab/r2017b</code>文件夹即可。<br>&nbsp;<br>安装选项中，笔者首先选择了全部安装，但symbolic_doc_en_common模块一直提示安装出错，无奈去掉了该模块的对勾，从目前跑的几个模型来看，该模块并无影响。</p>
<h4 id="挂载镜像文件dvd2"><a href="#挂载镜像文件dvd2" class="headerlink" title="挂载镜像文件dvd2"></a>挂载镜像文件dvd2</h4><p>安装到一半多，会提示载入dvd2，这时候重启一个终端，用相同的方式载入，点击<code>ok</code>直到安装结束即可<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> </span><br><span class="line">sudo mount -t auto -o loop /home/&lt;user name&gt;/xxx_dvd2.iso /home/&lt;user name&gt;/Matlab</span><br></pre></td></tr></table></figure></p>
<h4 id="结束安装"><a href="#结束安装" class="headerlink" title="结束安装"></a>结束安装</h4><p>删除不用的文件夹及卸载盘符<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -r /home/&lt;user name&gt;/Matlab  </span><br><span class="line">sudo umount /home/&lt;user name&gt;/Matlab</span><br></pre></td></tr></table></figure></p>
<h4 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> crack绝对路径</span><br><span class="line">sudo mkdir /home/&lt;user name&gt;/matlab/r2017b/bin/licenses/  </span><br><span class="line">sudo cp license_standalone.lic /home/&lt;user name&gt;/matlab/r2017b/bin/licenses/  </span><br><span class="line">sudo cp libmwservices.so /home/&lt;user name&gt;/matlab/r2017b/bin/glnxa64/</span><br></pre></td></tr></table></figure>
<h4 id="启动matlab"><a href="#启动matlab" class="headerlink" title="启动matlab"></a>启动matlab</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/&lt;user name&gt;/matlab/r2017b/bin</span><br><span class="line">sudo ./matlab</span><br></pre></td></tr></table></figure>
<p>第一次打开matlab会再次提示输入破解密钥，在对话框窗口中填入crack目录下的license_standalone.lic绝对路径即可。</p>
<h4 id="添加Matlab到系统路径"><a href="#添加Matlab到系统路径" class="headerlink" title="添加Matlab到系统路径"></a>添加Matlab到系统路径</h4><p>这里注意一点：路径如果写到/etc/profile，那么会影响到该服务器的所有用户。所以我们在~/.bashrc中进行配置即可<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/home/&lt;user name&gt;/Matlab/r2017b/bin</span><br></pre></td></tr></table></figure></p>
<p>笔者尝试第一种解决方案失败，遂采用了下一种，建立软连接到系统启动目录(注意建立软连接一定要使用绝对路径)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /home/&lt;user name&gt;/Matlab/r2017b/bin/matlab /usr/<span class="built_in">local</span>/bin/matlab</span><br></pre></td></tr></table></figure></p>
<h4 id="可能的问题"><a href="#可能的问题" class="headerlink" title="可能的问题"></a>可能的问题</h4><p><code>/usr/local/MATLAB/R2017b/bin/glnxa64/../../sys/os/glnxa64/libstdc++.so.6: version GLIBCXX_3.4.21 not found</code>，运行matlab时出现这样的错误提示是matlab g++版本<code>libstdc++.so.6.0.20</code>版本较低，复制高版本的lib，设置新的软连接即可<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loacte  libstdc++.so.6.0.21 <span class="comment"># 查看高版本lib路径</span></span><br><span class="line"><span class="built_in">cd</span> ~/&lt;user name&gt;/matlab/r2017b/sys/os/glnxa64</span><br><span class="line">sudo cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21 ./</span><br><span class="line">sudo rm -rf libstdc++.so.6</span><br><span class="line">sudo ln -s libstdc++.so.6.0.21 libstdc++.so.6</span><br></pre></td></tr></table></figure></p>
<h5 id="不通过sudo启动matlab"><a href="#不通过sudo启动matlab" class="headerlink" title="不通过sudo启动matlab"></a>不通过sudo启动matlab</h5><p>注意matlab是隐藏文件，前面有.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod -R a+rw ~/.matlab</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/27/ubuntusys-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/27/ubuntusys-2/" itemprop="url">Ubuntu1604装机系列(二)：Opencv安装</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-27T10:08:34+08:00">
                2018-03-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/27/ubuntusys-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/27/ubuntusys-2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><p>官网下载<code>opencv3.4.1</code>，选择source<a href="https://opencv.org/releases.html" target="_blank" rel="noopener">版本</a><br>官网下载<code>opencv3.4.1_contrib</code>，选择source<a href="https://opencv.org/releases.html" target="_blank" rel="noopener">版本</a></p>
<h4 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cp ../opencv3.4.1_contrib ./   <span class="comment"># 复制contrib到opencv3.4.1文件夹并重命名</span></span><br><span class="line"><span class="built_in">cd</span> opencv3.4.1</span><br><span class="line">mv opencv3.4.1_contrib opencv_contrib</span><br><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">ccmake ..</span><br><span class="line">几个要注意的修改项(cuda/python根据自己的安装路径来写)：</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CUDA_TOOLKIT_ROOT_DIR:		/home/&lt;user name&gt;/wuxj/cuda-8.0</span><br><span class="line">OPENCV_EXTRA_MODULES_PATH:	/home/&lt;user name&gt;/wuxj/opencv-3.4.1/opencv_contrib </span><br><span class="line">PYTHON2_EXECUTABLE:		/usr/bin/python2.7                           </span><br><span class="line">PYTHON2_INCLUDE_DIR:		/usr/include/python2.7 </span><br><span class="line">PYTHON2_NUMPY_INCLUDE_DIRS: 	/usr/<span class="built_in">local</span>/lib/python2.7/dist-packages/dist-packages/numpy/core/include  </span><br><span class="line">PYTHON2_PACKAGES_PATH:		/lib/python2.7/dist-packages </span><br><span class="line">CMAKE_INSTALL_PREFIX:		/home/&lt;user name&gt;/wuxj   <span class="comment"># make install的安装路径</span></span><br></pre></td></tr></table></figure>
<p><code>make -j8</code> # 等待安装成功即可 8：8核CPU，编译速度更快</p>
<p><code>make install</code> # 复制上一步build文件夹到<code>/home/&lt;user name&gt;/wuxj</code> 中，这时候wuxj文件夹会包含bin(exe)、include(头文件)、lib(动态库)、share4个文件夹</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/22/mac-opcv/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/22/mac-opcv/" itemprop="url">MacOS安装OpenCV</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-22T18:58:49+08:00">
                2018-03-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/22/mac-opcv/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/22/mac-opcv/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="更换Mac-brew-安装源，下载软件分分钟"><a href="#更换Mac-brew-安装源，下载软件分分钟" class="headerlink" title="更换Mac brew 安装源，下载软件分分钟"></a>更换Mac brew 安装源，下载软件分分钟</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="string">"<span class="variable">$(brew --repo)</span>"</span> &amp;&amp; git remote <span class="built_in">set</span>-url origin https://git.coding.net/homebrew/homebrew.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$home</span> &amp;&amp; brew update</span><br></pre></td></tr></table></figure>
<h5 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo brew install opencv</span><br></pre></td></tr></table></figure>
<h5 id="配置环境变量：安装好的opencv位于-usr-local-Cellar-下"><a href="#配置环境变量：安装好的opencv位于-usr-local-Cellar-下" class="headerlink" title="配置环境变量：安装好的opencv位于/usr/local/Cellar/下"></a>配置环境变量：安装好的opencv位于<code>/usr/local/Cellar/</code>下</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi .bash_profile</span><br><span class="line"><span class="built_in">export</span> DYLD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/Cellar/opencv/3.4.1_2/lib:<span class="variable">$DYLD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">source</span> .bash_profile <span class="comment"># 使路径生效（下同）</span></span><br></pre></td></tr></table></figure>
<h5 id="配置python环境变量"><a href="#配置python环境变量" class="headerlink" title="配置python环境变量"></a>配置python环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /Library/Python/2.7/site-packages/</span><br><span class="line"></span><br><span class="line">sudo ln -s /usr/<span class="built_in">local</span>/Cellar/opencv/3.4.1_2/lib/python2.7/site-packages/cv.py cv.py</span><br><span class="line">sudo ln -s /usr/<span class="built_in">local</span>/Cellar/opencv/3.4.1_2/lib/python2.7/site-packages/cv2.so cv2.so</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:/usr/<span class="built_in">local</span>/lib/python2.7/site-package  <span class="comment"># 将python路径写入系统目录</span></span><br></pre></td></tr></table></figure>
<h5 id="生成SDK还需要一个pkg-config，用来find-package位置"><a href="#生成SDK还需要一个pkg-config，用来find-package位置" class="headerlink" title="生成SDK还需要一个pkg-config，用来find package位置"></a>生成SDK还需要一个<code>pkg-config</code>，用来find package位置</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://pkgconfig.freedesktop.org/releases/pkg-config-0.29.tar.gz .</span><br><span class="line">env LDFLAGS=<span class="string">"-framework CoreFoundation -framework Carbon"</span> ./configure --with-internal-glib</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>
<h5 id="在系统路径中把cv路径写入到pkg-config"><a href="#在系统路径中把cv路径写入到pkg-config" class="headerlink" title="在系统路径中把cv路径写入到pkg-config"></a>在系统路径中把cv路径写入到<code>pkg-config</code></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi .bash_profile</span><br><span class="line">PKG_CONFIG_PATH=<span class="variable">$PKG_CONFIG_PATH</span>:/usr/<span class="built_in">local</span>/Cellar/opencv/3.4.1_2/lib/pkgconfig</span><br><span class="line"><span class="built_in">export</span> PKG_CONFIG_PATH</span><br></pre></td></tr></table></figure>
<h5 id="show-me-a-picture！"><a href="#show-me-a-picture！" class="headerlink" title="show me a picture！"></a>show me a picture！</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;   </span><br><span class="line">    Mat img = imread(<span class="string">"test.jpg"</span>, CV_LOAD_IMAGE_UNCHANGED);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(img.empty())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"failed to load input image\n"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    imshow(<span class="string">"Display Image"</span>, img);</span><br><span class="line">    waitKey(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// no need to release anything with c++ !   </span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>上述文件命名为test.cpp，用下面的指令编译成一个超简单的Demo</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -o <span class="built_in">test</span> test.cpp `pkg-config --libs opencv` `pkg-config --cflags opencv`</span><br></pre></td></tr></table></figure></p>
<p><code>./test</code>运行代码</p>
<h5 id="多个cpp文件工程的编译"><a href="#多个cpp文件工程的编译" class="headerlink" title="多个cpp文件工程的编译"></a>多个cpp文件工程的编译</h5><p>假如test文件下存在<code>imageRank.h</code>、<code>imageRank.cpp</code>、<code>main.cpp</code>文件<code>.h</code>文件不用管，在编译.cpp时会自动调用。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">g++ -c imageRank.cpp -o imageRank.o -I ./   <span class="comment"># 先编译函数cpp文件</span></span><br><span class="line">g++ main.cpp imageRank.o -o main `pkg-config --libs opencv` `pkg-config --cflags opencv`  <span class="comment"># 直接生成可执行文件</span></span><br><span class="line">ar -r libimageRank.a imageRank.o  <span class="comment"># 或者编译出静态库文件给第三方</span></span><br><span class="line">g++ -o main -L. -ldetection main.cpp `pkg-config --libs opencv` `pkg-config --cflags opencv`</span><br><span class="line">生成可执行文件</span><br></pre></td></tr></table></figure></p>
<p>Ref：<br> 📎：<a href="https://www.jianshu.com/p/3d149f167b41" target="_blank" rel="noopener">Mac OS X 安装并测试 OpenCV</a><br> 📎：<a href="http://www.voidcn.com/article/p-yxftfwnu-on.html" target="_blank" rel="noopener">mac os 安装 pkg-config</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/14/nvidia/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/14/nvidia/" itemprop="url">Ubuntu1604装机系列(一)：Mac烧系统盘及1080Ti显卡(390版本)驱动安装</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-14T12:43:14+08:00">
                2018-03-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/14/nvidia/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/14/nvidia/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="Ubuntu1604系统安装"><a href="#Ubuntu1604系统安装" class="headerlink" title="Ubuntu1604系统安装"></a>Ubuntu1604系统安装</h4><p>笔者第一次尝试Mac烧系统盘，没想到比windows简单到爆，过程如下：<br>&nbsp;<br><a href="https://www.ubuntu.com/download" target="_blank" rel="noopener">官网</a>下载Ubuntu iso文件<br>&nbsp;<br>格式化一个U盘<br>&nbsp;<br>接着写入U盘镜像<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df -hl       <span class="comment"># 记住磁盘名称，Eg：/dev/disk2s</span></span><br><span class="line">sudo diskutil umount /dev/disk2s  <span class="comment"># 卸载该磁盘</span></span><br><span class="line">sudo dd bs=1m <span class="keyword">if</span>=/Users/&lt;user name&gt;/Desktop/ubuntu-16.04.4-desktop-amd64.iso of=/dev/disk2s</span><br></pre></td></tr></table></figure></p>
<p>静静等待10分钟，U盘即可写入完毕。接着就是设置电脑U盘启动，开始安装Ubuntu系统了</p>
<h5 id="ubuntu-换源"><a href="#ubuntu-换源" class="headerlink" title="ubuntu 换源"></a>ubuntu 换源</h5><p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/" target="_blank" rel="noopener">清华大学开源软件镜像站</a>寻找对应系统的源<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/apt</span><br><span class="line">sudo cp sources.list sources.list.old <span class="comment">#先将之前的源做个备份</span></span><br><span class="line"></span><br><span class="line">vi sources.list <span class="comment"># 拷贝清华的镜像到该list</span></span><br><span class="line"></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse</span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse</span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse</span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiver</span><br><span class="line"></span><br><span class="line">sudo apt-get update <span class="comment"># 更新源完成，发现网速飞快了</span></span><br></pre></td></tr></table></figure></p>
<h5 id="apt-get相关常用指令"><a href="#apt-get相关常用指令" class="headerlink" title="apt-get相关常用指令"></a>apt-get相关常用指令</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update  更新源</span><br><span class="line">sudo apt-get install package 安装包</span><br><span class="line">sudo apt-cache search package 搜索软件包</span><br><span class="line">sudo apt-get remove package --purge 删除包，包括配置文件等</span><br></pre></td></tr></table></figure>
<h4 id="显卡驱动安装"><a href="#显卡驱动安装" class="headerlink" title="显卡驱动安装"></a>显卡驱动安装</h4><p>Nvidia显卡驱动踩了很多坑，到网上百度了N多教程，大致尝试的如下：</p>
<blockquote>
<ul>
<li>显卡线插集显上，装好驱动后把线再插回N卡</li>
<li>BIOS设置禁用Secure boot，cpu做显卡</li>
<li>采用PPA源，尝试各种375、381、390的安装</li>
<li>打开ubuntu的软件更新，更新显卡驱动</li>
</ul>
</blockquote>
<p>经过上述步骤，会提示显卡驱动已经安装成功，但<code>nvidia-smi</code>依然无效…该最简单但最高效的选手登场了</p>
<h5 id="编译-NVIDIA-驱动程序"><a href="#编译-NVIDIA-驱动程序" class="headerlink" title="编译 NVIDIA 驱动程序"></a>编译 NVIDIA 驱动程序</h5><p>Nvidia官网下载最新的显卡<a href="https://www.geforce.cn/drivers" target="_blank" rel="noopener">驱动程序</a>，ubuntu的一般就几十兆左右。<br>&nbsp;<br>将<code>nouveau driver</code>加入黑名单<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options modset=0</span><br></pre></td></tr></table></figure></p>
<p>终端输入<code>lspci | grep nouveau</code>，如果没有显示证明该驱动被kill</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot <span class="comment"># 一定要重启</span></span><br></pre></td></tr></table></figure>
<p>杀掉<code>LightDM</code>或<code>GDM</code>登录显示器，进入纯文本<code>tty1</code>模式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm stop</span><br><span class="line">sudo dpkg-reconfigure gdm <span class="comment"># 有的人可能安装的不是LightDM界面，可先通过该命令切到LightDM，或者直接stop GDM等界面(第二种笔者未尝试)</span></span><br></pre></td></tr></table></figure></p>
<p>编译安装NVIDIA驱动，此过程大约耗时3～5分钟<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod +x NVIDIA-xxx.run</span><br><span class="line">sudo ./NVIDIA-xxx.run</span><br></pre></td></tr></table></figure></p>
<p>需要注意的：<br>1、此处认真看提示，并不是一路选择”yes”。<br>2、假如上一步在安装时，Warning了gcc版本不对，则退出驱动安装，先安装对应版本的gcc之后再继续。笔者安装的驱动程序提示需要gcc-5.4.0，又是一番折腾，还好在冯博的指导下，找到了精干快速的方法。不介意的话可以移步笔者之前的文章<a href="http://localhost:4000/2018/02/25/gcc/" target="_blank" rel="noopener">Ubuntu下gcc/g++多版本切换</a><br>&nbsp;<br>安装成功后，重新开启桌面测试。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm start</span><br><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure></p>
<p>成功后的截图<br> <img src="/img/nvidia.png" width="550" alt="图片名称" align="center"></p>
<h4 id="Ref："><a href="#Ref：" class="headerlink" title="Ref："></a>Ref：</h4><p> 📎：<a href="https://www.linuxidc.com/Linux/2011-07/39491.htm" target="_blank" rel="noopener">Ubuntu下轻松切换GDM, LightDM , KDM</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/08/rcnn-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/08/rcnn-1/" itemprop="url">论文笔记：《Faster R-CNN》</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-08T20:44:25+08:00">
                2018-03-08
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/08/rcnn-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/08/rcnn-1/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p>Faster R-CNN检测速度更快(5fps/s)，是Fast R-CNN的10倍，R-CNN的250倍，检测精度则稍好于Fast版本。主要贡献就是采用卷积网络提取Region proposal，取代了传统的Selective search算法。</p>
<h4 id="RPN网络概述"><a href="#RPN网络概述" class="headerlink" title="RPN网络概述"></a>RPN网络概述</h4><p>Faster R-CNN提出了Region Proposal Network（RPN）思想，它与物体特征提取网络共享较低层卷积信息。具体方法：以feature map上每个特征点为中心，选取其周围$[n,n]$的窗口区域，进行滑动。再根据缩放关系换算到源图，假如某个窗口与ground truth计算的IOU值大于某个阈值，则认为该窗口内存在物体。<br>&nbsp;<br>为了增加多尺度检测能力，每个特征点换算到原图后，会将原图的窗口进行调大或调小操作。论文中作者一共设置了9种(窗口面积为 {128, 256, 512} x 长宽比为 {1:1, 1:2, 2:1})。原图中的窗口为了和feature map窗口进行区分，称为<code>anchor</code>。直观来看，如下图所示：<br><img src="/img/frcnn7.png" width="300" alt="图片名称" align="center"></p>
<h5 id="RPN训练阶段"><a href="#RPN训练阶段" class="headerlink" title="RPN训练阶段"></a>RPN训练阶段</h5><blockquote>
<ul>
<li>对于[60, 40]大小的一张feature map，那么原图中可能的anchor数目约为$60\ast 40\ast 9 \approx 20000$个</li>
<li>忽略超出边界的anchors剩下6000个</li>
<li>通过anchor与ground truth计算的IOU值，可以进行每个anchor为前景$or$背景的自动标注，即：输入RPN网络的训练样本为box坐标 + box内是否有物体。</li>
<li>同样采用多任务训练，完成前、背景分类及bounding box的粗回归。</li>
</ul>
</blockquote>
<h5 id="RPN测试阶段"><a href="#RPN测试阶段" class="headerlink" title="RPN测试阶段"></a>RPN测试阶段</h5><blockquote>
<ul>
<li>RPN网络对每幅图的6000个region均映射为一个概率值score和对应的四个坐标值。</li>
<li>然后利用该score对6000个regions进行NMS非极大抑制，筛选到约为2000个anchor。</li>
<li>接着再筛选出Top-N(论文中N=300)个区域用于Fast RCNN detect网络的训练(作者在论文中对2000、300个region proposal进行对比实验，效果差别不大，也进一步说明了RPN提取region的有效性、针对性)</li>
</ul>
</blockquote>
<h5 id="RPN网络结构"><a href="#RPN网络结构" class="headerlink" title="RPN网络结构"></a>RPN网络结构</h5><p>作者在论文中给出的一张图有些误导，查阅前辈们写的博客时候才理解RPN网络具体形式。重新绘制网络结构如下：</p>
<p><img src="/img/frcnn_1.png" width="600" alt="图片名称" align="center"></p>
<p>论文中提到的256-d，不是整个feature map生成一个256维的向量，feature map上的每一个“点”都对应一个256维向量。同时该“点”对应了9个anchors，18个cls输出，36个reg输出。<br>&nbsp;<br><strong>小结：</strong>RPN的基本思想就是通过对feature map进行窗口滑动，再在该窗口上累加一个小网络，最终训练得到某些可能为前景的regions，以及该regions对应的bouning box。<font color="red">该网络专门判断该区域是否存在物体，而并不检测是哪种特定的物体。</font></p>
<h4 id="RPN-Fast-RCNN"><a href="#RPN-Fast-RCNN" class="headerlink" title="RPN + Fast RCNN"></a>RPN + Fast RCNN</h4><p>有了RPN后，怎样跟Fast RCNN连接起来呢？作者采用了叫做<code>4-Step Alternating Training</code>的方式：<br><strong>step 1 :</strong>采用预训练的VGG网络，前13层用作特征提取层，后面的网络采用RPN架构，用均值为0的高斯分布随机初始化网络参数<br><strong>step 2 :</strong>同样采用预训练的VGG前13层网络，用step 1中 RPN得到的region proposal，进行Fast RCNN网络的训练。这两步还未实现共享卷积层<br><strong>step 3 :</strong>采用step 2中Fast RCNN的卷积层参数初始化RPN网络，并固定共享层网络参数，仅仅fine tune RPN网络层参数，得到新的region proposal<br><strong>step 4 :</strong>继续固定共享层网络参数，仅仅fine tune Fast RCNN，得到最终的模型。</p>
<h4 id="Fast-RCNN-与-Faster-RCNN结果对比"><a href="#Fast-RCNN-与-Faster-RCNN结果对比" class="headerlink" title="Fast RCNN 与 Faster RCNN结果对比"></a>Fast RCNN 与 Faster RCNN结果对比</h4><p><img src="/img/frcnn_2.png" width="500" alt="图片名称" align="center"></p>
<h4 id="Faster-RCNN网络结构-来源于网络"><a href="#Faster-RCNN网络结构-来源于网络" class="headerlink" title="Faster RCNN网络结构(来源于网络)"></a>Faster RCNN网络结构(来源于网络)</h4><p><img src="/img/frcnn1.jpg" width="600" alt="图片名称" align="center"></p>
<h3 id="Ref："><a href="#Ref：" class="headerlink" title="Ref："></a>Ref：</h3><p>📎：<a href="http://blog.csdn.net/wfei101/article/details/77150573" target="_blank" rel="noopener"> 区域推荐网络RPN
</a><br>📎：<a href="http://blog.csdn.net/sloanqin/article/details/51545125" target="_blank" rel="noopener">faster-rcnn 之 RPN网络的结构解析</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/07/rcnn-0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/07/rcnn-0/" itemprop="url">论文笔记：《Fast R-CNN》</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-07T20:44:25+08:00">
                2018-03-07
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/07/rcnn-0/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/07/rcnn-0/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP Net"></a>SPP Net</h3><p>R-CNN的进阶版Fast R-CNN可以说是在RCNN的基础上采纳了<a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener">SPP Net</a>方法，使得性能进一步提高。所以有必要先了解下何凯明提出的SPP Net。SPP:Spatial Pyramid Pooling（空间金字塔池化）。他有两个显著的特点：<br>&nbsp;<br><strong><font color="blue"> 创新点1：实现CNN的多尺度输入，忽略图片尺寸的影响 </font></strong><br>为了实现全联接层可以正确匹配pooling层后的维度，R-CNN中笔者先对Region proposal Crop到某一固定维度，但这样会造成一定的图像失真。有没有不Crop图像从而实现维度匹配的方法呢？一是调整最后的pooling层维度，二是调节全联接层的结构，使它接受任意维度特征。后一种方法是全卷积网络(FCN)，本文是采用的是前一种，即SPP：空间金字塔pooling。<br>&nbsp;<br>SPP的具体实现方式：假设与全联接层匹配的最后一个pooling层，输出维度应当是$[2\ast 2]$。而此时<code>ROI</code>区域的大小为$[5\ast 7]$(Region proposal在该论文中又称为<code>ROI</code>区域)。那么此时pooling核的size应当为$[\frac{5}{2} \ast \frac{7}{2}]$，才能使该ROI区域pooling后，得到匹配的size。但核的size不能为小数啊，所以采用理论size做间隔，最后向下取整得到每个pooling核的size。<br><img src="/img/frcnn1.png" width="350" alt="图片名称" align="center"><br>如上图所示：H方向以2.5为间隔$[0, 2.5, 5]$，W方向以3.5取间隔$[0, 3.5, 7]$。最后每个pooling核<strong>起始点</strong>坐标为H:$[2, 5]$，W:$[3, 7]$。更广泛地，我们用$[h, w]$代表<code>ROI</code>区域的高和宽，$[H, W]$代表希望pooling后得到的高和宽。那么每个网格动态调整后的大小为$[\frac{h}{H} \ast \frac{w}{W}]$。<br><strong>小结：SPP说到底就是计算一个比例关系，以动态调整pooling核的大小，实在是非常简单</strong></p>
<p><strong><font color="blue"> 创新点2：只对原图提取一次卷积特征 </font></strong><br>RCNN中，一张图片Region proposal的数量为2K个，其中存在大量的重复区域。而用CNN提取这些Region，显然是非常复杂的一件事儿。SPP Net中的做法是对整张图像用CNN仅提取一次特征，feature map一般计算到最后一个pooling层。接着再根据相应的缩放比例，对源图的Regions进行一一映射，找到其在feature map的位置即可。该算法看似简单，但对于regions的特征提取，速度提升约146倍。</p>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p>Fast R-CNN是在SPP Net基础上做的进一步改进，作者把<strong>SVM分类器换成Softmax，和CNN整合成一个网络，同时把bounding box regression也整合进网络中，三层联动调节参数，从而带来了效果的进一步提升。</strong>Fast RCNN架构如图所示：<br><img src="/img/frcnn3.jpeg" width="600" alt="图片名称" align="center"><br>该网络是典型的多任务学习，低层的卷积层参数共享(采用VGG16提取特征)，高层分别训练分类及回归网络。多任务学习一般用在task具有一定相似度的情境下。网络总的损失函数是两部分乘系数相加$L = L_{cls} + \lambda \times L_{loc}$，对于$L_{cls} $采用softmax-loss损失函数，对于Bounding box regression采用特殊的一种损失函数，如下：<br>$$L_{loc}(t^{u}, v) = \sum_{i = {x,y,w,h}}smooth_{L1}(t_{i}^{u}-v_{i})$$<br>$$if \left | x \right |&lt;1 \qquad smooth_{L1}(x) =0.5x^{2}  \qquad || \qquad Otherwise \qquad smooth_{L1}(x) = \left | x \right | -1 $$<br>这部分没有深究，其中$t_{i}, v_{i}$分别代表Region proposal和ground truth的坐标。Fast R-CNN的联合损失函数可以直接进行反向传播，从而达到端到端训练的目的。</p>
<h3 id="Ref："><a href="#Ref：" class="headerlink" title="Ref："></a>Ref：</h3><p>📎：<a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">Fast RCNN</a><br>📎：<a href="http://jermmy.xyz/2018/01/15/2018-1-15-paper-notes-fast-er-rcnn/" target="_blank" rel="noopener">论文笔记：Fast(er) RCNN</a><br>📎：<a href="https://zhuanlan.zhihu.com/p/22190532" target="_blank" rel="noopener">一箭N雕：多任务深度学习实战</a><br>📎：<a href="http://shartoo.github.io/RCNN-series/" target="_blank" rel="noopener">RCNN,Fast RCNN,Faster RCNN 总结</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/05/Rcnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/05/Rcnn/" itemprop="url">论文笔记：《R-CNN》</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-05T20:20:45+08:00">
                2018-03-05
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/05/Rcnn/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/05/Rcnn/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>本篇文章要介绍的，是神经网络应用于物体检测领域的开山鼻祖R-CNN：Regions with CNN features。检测整体框架如下图所示，相信在读过<strong>Selective Search</strong>的论文后，对上图的架构并不陌生(不介意的可移步笔者对<a href="http://localhost:4000/2018/03/03/Search/" target="_blank" rel="noopener">Selective Search</a>的解读)<br><img src="/img/rcnn1.png" width="700" alt="图片名称" align="center"><br><strong>R-CNN物体检测的步骤如下：</strong></p>
<blockquote>
<ul>
<li>输入源图，通过Selective Search算法，提取2k个左右的待选区域Regions</li>
<li>对每个Region进行Crop/Scale，缩放到同样的尺寸(为了与CNN网络最后的全联接层对齐)</li>
<li>之后对每个Region利用Pre-train的AlexNet，抽取特征(替代DPM、HOG等传统算子)(pool5 feature)[维度：4096]</li>
<li>将这些特征丢入SVM分类器(二分类)进行训练，得到的就是一个region-bbox以及对应的类别。SVM权值矩阵[4096, N]，N:类别数</li>
<li>采用NMS非极大抑制算法，删除大量SS算法产生的重复区域</li>
<li>最后利用pool5 feature，训练一个线性回归模型，提高bounding box精度</li>
</ul>
</blockquote>
<h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><p>从上述流程看，<code>R-CNN</code>与<code>Selective Search</code>模型差别不大，主要就是在特征提取部分，采用了2012年<code>ILSVRC：ImageNet Large Scale Visual Recognition Chal- lenge</code>竞赛冠军网络AlexNet，其结构如图所示：<br><img src="/img/rcnn2.png" width="700" alt="图片名称" align="center"></p>
<h4 id="创新点1：采用CNN提取图像特征"><a href="#创新点1：采用CNN提取图像特征" class="headerlink" title="创新点1：采用CNN提取图像特征"></a>创新点1：采用CNN提取图像特征</h4><p>由于Alexnet参数众多，但<code>PASCAL VOC</code>任务又不像分类任务，标注难度大，数据量较少，直接训练容易造成过拟合。所以作者是对预训练的AlexNet进行<code>fine-tuning</code>。<br>&nbsp;<br>具体做法是将<code>FC-7</code>层的1000维向量更改为21维(包括20个类及背景)，并随机初始化这一全连接层的参数。训练样本的正样本来源是<code>PASCAL VOC</code>中人工标注的bounding box区域及类别；正样本是与<code>bounding box</code>计算的IoU值&gt;=50%的Regions(这些候选Regions通过SS算法得到)。对图像进行一定程度的Crop，同时设定好batchsize、lr、SGD等超参数，进行迭代训练。<strong>需要注意这里的神经网络参数是单独训练得到的</strong><br>&nbsp;<br>提取上图中<code>Pool5</code>层的特征，作为类别的特征向量，存到硬盘中，之后再训练一个SVM二分类器，如图所示(图片来源<a href="https://www.cnblogs.com/skyfsm/p/6806246.html" target="_blank" rel="noopener">冠军的试炼</a>)。对于20类，即训练20个SVM二分类器。但与CNN不同的，作者通过实验，重新设置了IoU的阈值为0.3，也就是将IoU&gt;=30%的Regions都当作正样本。<br><img src="/img/rcnn3.png" width="700" alt="图片名称" align="center"></p>
<h4 id="创新点2：SVM分类后采用线性回归模型精绘bounding-box"><a href="#创新点2：SVM分类后采用线性回归模型精绘bounding-box" class="headerlink" title="创新点2：SVM分类后采用线性回归模型精绘bounding box"></a>创新点2：SVM分类后采用线性回归模型精绘bounding box</h4><h5 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h5><p>由于SS算法对某个类的bounding box框的不够完美，所以训练一个回归模型，作者论文中采用<code>Bounding-box regression</code>提升了3.5个map。选取的Regions与人工标注的bounding box IoU应当&gt;=0.6，并且仅选取IoU最大的那个作为候选Region。（此处IoU设置比较严格，作者发现如果假设函数与<code>bounding box</code>差距太大话，是学不到东西的）<br>&nbsp;<br>总体目标就是对Region进行两次平移$\Delta x, \Delta y$，再进行两次缩放$S_{x}, S_{y}$。简单说就是输入<code>pool5</code>层的特征向量，经过4次运算后，得到更加精确的bounding box区域。论文公式如下，就是比较简单的线性回归，损失函数采用梯度下降进行优化。<br><img src="/img/rcnn4.png" width="350" alt="图片名称" align="center"><br><img src="/img/rcnn5.png" width="500" alt="图片名称" align="center"><br>其中$d_{x}(P)$、$d_{y}(P)$为平移算术因子，$d_{w}(P)$、$d_{h}(P)$为尺度缩放算术因子。以其中的$d_{x}(P)$来说：它的实际值就是$w\phi$，为权重w乘以特征向量的形式。而其理论值是$t_{\ast }^{i}$，可以通过对(1)、(2)、(3)、(4)变换得到。最终梯度下降的优化目标便是通过最小化均方误差函数来求解该w矩阵。</p>
<h5 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h5><p>训练阶段，我们可以采用IoU最大的Region进行训练，那test阶段呢？同一物体便可能包含大量重复的矩形框，这里作者采用的是<strong>非极大值抑制（non-maximum suppression）</strong>方法对这些区域进行筛选。<strong>NMS基于一个窗口区域被认为是最有可能表示某一个物体的时候，那么和这个窗口区域交叉面积大的proposal就可以认为不是需要的窗口区域。</strong><br>&nbsp;<br>具体思路为：从所有矩形框(Regions)中(不分类别)选取SVM分类器得分最高的Region，将与该Region IoU面积超过阈值的都删除。再从剩余的矩形框中选取SVM得分最高的Region，重复上述步骤，直到没有矩形框可选为止。</p>
<h3 id="CNN特征提取相关："><a href="#CNN特征提取相关：" class="headerlink" title="CNN特征提取相关："></a>CNN特征提取相关：</h3><h4 id="CNN为什么选取pool5层的特征？"><a href="#CNN为什么选取pool5层的特征？" class="headerlink" title="CNN为什么选取pool5层的特征？"></a>CNN为什么选取<code>pool5</code>层的特征？</h4><p>真实答案是如果不对模型进行<code>fine-tuning</code>，那么采用<code>pool5</code>、<code>fc6</code>、<code>fc7</code>特征训练的SVM分类器，性能是相似的；如果对模型用VOC数据<code>fine-tuning</code>，利用这些特征训练的分类器性能都会提升，而<code>fc6</code>、<code>fc7</code>会进一步得到更大提升，如下所示：<br><img src="/img/rcnn6.png" alt=""></p>
<h4 id="为什么不直接采用CNN端到端训练，而要接一个SVM？"><a href="#为什么不直接采用CNN端到端训练，而要接一个SVM？" class="headerlink" title="为什么不直接采用CNN端到端训练，而要接一个SVM？"></a>为什么不直接采用CNN端到端训练，而要接一个SVM？</h4><p>VOC数据集较小，如果直接端到端训练，CNN十分容易过拟合。而SVM则适合小样本训练，所以最后采用SVM进行分类</p>
<p><strong>PS：CNN的尺度不变性：</strong>并不是一定不变，而是大概率不变。比如对于两幅size不同，内容相同的图像。假设某个卷积核提取的是图像边缘信息，那么对其<code>Feature map</code>进行<code>Maxpooling</code>操作后，都会把梯度最大值提取出来，调整Pooling的<code>size</code>或<code>stride</code>，很大概率会得到相同的<code>map</code>图。</p>
<h3 id="RCNN存在四个明显问题："><a href="#RCNN存在四个明显问题：" class="headerlink" title="RCNN存在四个明显问题："></a>RCNN存在四个明显问题：</h3><p>1、多个候选区域对应的图像需要预先提取，占用较大的磁盘空间；<br>2、针对传统CNN需要固定尺寸的输入图像，crop/warp（归一化）产生物体截断或拉伸，会导致输入CNN的信息丢失；<br>3、每一个ProposalRegion都需要进入CNN网络计算，上千个Region存在大量的范围重叠，重复的特征提取带来巨大的计算浪费。<br>4、CNN、SVM、回归模型需要按顺序，进行单独训练，不能端到端训练。</p>
<h3 id="Ref："><a href="#Ref：" class="headerlink" title="Ref："></a>Ref：</h3><p>📎：<a href="http://www.rossgirshick.info/" target="_blank" rel="noopener">Rbg大神个人主页，包含论文、slides、code等</a><br>📎：<a href="https://www.cnblogs.com/skyfsm/p/6806246.html" target="_blank" rel="noopener">基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN</a><br>📎：<a href="http://blog.csdn.net/linolzhang/article/details/54344350" target="_blank" rel="noopener">目标检测-RCNN系列</a><br>📎：<a href="http://jermmy.xyz/2017/05/08/2017-5-8-paper-notes-rcnn/" target="_blank" rel="noopener">论文笔记：Rich feature hierarchies for accurate object detection and semantic segmentation</a><br>📎：<a href="http://blog.csdn.net/u011534057/article/details/51218250" target="_blank" rel="noopener">RCNN学习笔记</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/03/Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/03/Search/" itemprop="url">论文笔记：《Selective Search for Object Recognition》</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-03T16:31:39+08:00">
                2018-03-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/03/Search/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/03/Search/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>即将学习基于R-CNN的图像目标检测(Object Recognition)，不得不提的一篇论文是《Selective Search for Object Recognition》，虽然仅用了传统的机器学习算法<code>Selective Search + DPM/Hog特征 + SVM分类器</code>，但其结构简单，可解释性强，对后面的Deep Learning物体检测模型，都有很大的借鉴意义。<br>&nbsp;<br>本篇论文的创新点在于选择性搜索算法(Selective Search)。不同于传统的蛮力搜索(Exhaustive Search)：需要不断改变窗口大小，遍历整张图像。Selective Search可以选择性地找出物体可能的存在区域，节省了大量不必要的特征提取开销。<br>&nbsp;<br><strong>结论先行：</strong>如图红色的区域便是<code>Selective Search算法</code>提取的可能存在物体的窗口：<br><img src="/img/ss.png" width="400" alt="图片名称" align="center"></p>
<h3 id="Selective-Search算法描述"><a href="#Selective-Search算法描述" class="headerlink" title="Selective Search算法描述"></a>Selective Search算法描述</h3><p>文章一开始便用这4幅图，说明了同一物体组成成分多样性的问题。图1显示了区分桌子和它上面的餐具需要利用一定的层次关系；图2的猫需要通过颜色来区分；图3的变色龙颜色不行，需要通过纹理特征(texture)来区分；图4中的车和车轮看似粘连在一起，但我们可以通过颜色、纹理两种特征加以区分。<br><img src="/img/ss1.png" width="400" alt="图片名称" align="center"><br><strong>小结：</strong>这样的特性说明了两个问题，物体识别时候，需要充分考虑图像物体的多样性（diversity），单一特征可能分得乱七八糟；另外，图像中物体布局有一定的层次（hierarchical）关系，在算法中的体现就是从小区域开始，一步步分层而上进行合并。</p>
<h3 id="Selective-Search算法详解"><a href="#Selective-Search算法详解" class="headerlink" title="Selective Search算法详解"></a>Selective Search算法详解</h3><p>Selective Search算法对传统的exhaustive search从以下两方面进行了改进：</p>
<blockquote>
<ul>
<li>采用多种先验知识对各个区域进行判别，避免一些无用的搜索，提高速度和精度</li>
<li>Selective Search只负责快速生成可能存在物体的窗口，并不做具体的特征检测</li>
</ul>
</blockquote>
<h4 id="执行流程图"><a href="#执行流程图" class="headerlink" title="执行流程图"></a>执行流程图</h4><p><img src="/img/ss2.png" width="500" alt="图片名称" align="center"><br><strong>重点翻译：</strong></p>
<blockquote>
<ul>
<li>input:彩色图像</li>
<li>output:物体可能的位置（很多个矩形坐标）</li>
<li>首先借助这篇<a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="noopener">论文</a>的方法，对图像实现一个粗略的分割：R = r1, r2…rn。调用方式比较简单，不再赘述，但要注意源图需是.ppm格式</li>
<li>初始化一个空集S</li>
<li>计算所有相邻区域之间的<strong>相似度</strong>，并放入S中(实质存放的是一个区域对，及其相似度信息)</li>
<li>找出S中相似度最高的两个区域进行合并，Eg：r1, r2，进行合并为r_t1。删除S中所有与r1, r2相邻的元素，并重新计算r_t1与周围相邻区域的相似度，放入集合S中，并将r_t1放入另一个集合R中。重复这个步骤，直到S为空。此时所有小区域被合并成为原图的大小，但每次的合并信息，都被存放在了集合R中，最后的<code>Combining Locations</code>便是对R中的区域进行标号排序。</li>
<li>从R中找出所有被标号的区域，计算其bounding box，便得到output。</li>
</ul>
</blockquote>
<p>PS：以上第三步的图像分割方法中考虑场景以及光照条件等影响，采用了RGB、灰度、HSV等8种颜色空间进行分割计算</p>
<h4 id="相似度计算方式"><a href="#相似度计算方式" class="headerlink" title="相似度计算方式"></a>相似度计算方式</h4><p>相似度计算直接影响合并区域顺序，对最终的检测结果，有至关重要的影响。此处同样综合了多种维度的相似度信息，分别是颜色（color）相似度、纹理（texture）相似度、大小（size）相似度和吻合（fit）相似度，最终将4种相似度计算结果，用如下公式合并：<br>$${s(r_{i}, r_{j})= a_{1}s_{colour}(r_{i}, r_{j}) + a_{2}s_{texture}(r_{i}, r_{j})<br>+a_{3}s_{size}(r_{i}, r_{j}) +a_{4}s_{fill}(r_{i}, r_{j})}$$</p>
<h5 id="这里仅就图像的颜色空间相似度进行介绍"><a href="#这里仅就图像的颜色空间相似度进行介绍" class="headerlink" title="这里仅就图像的颜色空间相似度进行介绍"></a>这里仅就图像的颜色空间相似度进行介绍</h5><p>颜色是区分不同物体的一个重要因素，文中将每个Region的颜色信息统计成一个75维的直方图，即每一个颜色通道为25bins的直方图(255/25 == 9，25bins的意思就是每隔9个数值统计像素数量)，之后用<strong>L1范数</strong>进行归一化(除以各维度绝对值之和)。相似度计算方式如下：<br>$$s_{colour}(r_{i}, r_{j}) = \sum_{k=1}^{n}min(c\tfrac{k}{i},c\tfrac{j}{k})$$<br>其实质就是计算两个直方图的交集，而新的区域特征向量采用如下与区域面积加权的方式实现。<br>$$C_{t} = \frac{size(r_{i})\ast C_{i}+size(r_{j})\ast C_{j}}{size(r_{i})+size(r_{j})}$$<br>而新区域面积就是两个源区域面积的简单相加$size(r_{i})+size(r_{j})$</p>
<h4 id="Combining-Locations"><a href="#Combining-Locations" class="headerlink" title="Combining Locations"></a>Combining Locations</h4><p>完成上述步骤，提取出了图像中大量的bounding box区域，而实际存在物体的区域可能只有其中的几个，这时候便需要对备选的bounding box赋予一定的优先级，从而进一步缩小后文特征提取的范围，文中称这一步处理为<code>Combining Locations</code>。<br>&nbsp;<br>具体方法为：因为Selective Search是一个逐步合并的层级结构，所以最大的一张图标为’1’，合并成’1’的子图标为’2’、’3’，以此类推。但这样的话会造成越大的bounding box排序越靠前。所以作者又加入了一定的shuffle机制，即在每个序号前，乘上一个随机数$RAND\in (0,1)$。通过新计算出的数值，按从小到大排序，得出Region最终的排序结果。一般candidates数量为2K个</p>
<h3 id="Object-Recognition目标识别"><a href="#Object-Recognition目标识别" class="headerlink" title="Object Recognition目标识别"></a>Object Recognition目标识别</h3><p>接下来采用HOG/DPM等算子分别提取正负样本特征，加入SVM分类器进行训练，整个架构如图所示：<br><img src="/img/ss3.png" width="800" alt="图片名称" align="center"><br>其中正样本为人工标注的bounding box，负样本为与正样本重叠程度20%~50%的Regions。特别地，删去负样本中，彼此重叠程度&gt;70%的Regions。重复迭代过程中再加入hard negative example进行训练。<br>PS：重叠程度即IoU(intersection-over-union，是一个定位精度的评价标准)参数，计算图示如下所示：<br><img src="/img/ss4.png" width="300" alt="图片名称" align="center"></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>📎：《Selective Search for Object Recognition》<br>📎：<a href="https://github.com/AlpacaDB/selectivesearch" target="_blank" rel="noopener">Selective Search算法的python实现</a><br>📎：<a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="noopener">Graph Based Image Segmentation</a><br>📎：<a href="http://blog.csdn.net/niaolianjiulin/article/details/52950797#t2" target="_blank" rel="noopener">http://blog.csdn.net/niaolianjiulin/article/details/52950797#t2</a><br>📎：<a href="http://jermmy.xyz/2017/05/04/2017-5-4-paper-notes-selective-search/" target="_blank" rel="noopener">http://jermmy.xyz/2017/05/04/2017-5-4-paper-notes-selective-search/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/03/signal/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="祥吉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Coding">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/03/signal/" itemprop="url">信号相关知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-03T16:31:13+08:00">
                2018-03-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/03/signal/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2018/03/03/signal/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="傅立叶级数"><a href="#傅立叶级数" class="headerlink" title="傅立叶级数"></a>傅立叶级数</h3><p>周期为T的周期信号，若满足“狄里赫利”条件，则可以将其展开为有限或无限个离散的正余弦函数累加的形式。它的物理意义是很明显的，这就是把一个比较复杂的周期运动看成许多不同运动的叠加，如下：<br>$$f(t) = A_{0}+\sum_{n=1}^{\infty }A_{n}sin(n\omega t + \varphi )$$<br>而对于任何一个非周期信号，同样可以用傅立叶展开的形式，只不过它的频域曲线是连续的(后文有涉及)，在计算上也从累加符号变成了积分符号。两者的关系如下：<br><img src="/img/fft.jpg" width="500" alt="图片名称" align="center"><br>那傅立叶变换的用处是什么？给你一个正弦曲线，让你从中拿走某个频率的分量（即滤波），时域图中基本无法看懂，频域中只要拿走几条竖线就好了。而在反向传播算法中，FFT可以把微分、积分，在频域中变为加减乘除的简单运算。</p>
<h3 id="时域-amp-频域"><a href="#时域-amp-频域" class="headerlink" title="时域&amp;频域"></a>时域&amp;频域</h3><p><strong>时域</strong>反应的是现实世界中我们最能感知的信号，横轴为时间，纵轴为振幅；而<strong>频域</strong>反应的是频率与振幅的关系。将一个表示波的函数从时域转化为频域的关系，便称为傅立叶变换。两个例子如下所示：<br><img src="/img/ft2.jpeg" width="600" alt="图片名称" align="center"></p>
<p>PS：玄学傅立叶：</p>
<blockquote>
<p>我们看似不规律的事情反而是规律的正弦波在时域上的投影，而正弦波又是一个旋转的圆在直线上的投影。<br>我们眼中的世界就像皮影戏的大幕布，幕布的后面有无数的齿轮，大齿轮带动小齿轮，小齿轮再带动更小的。在最外面的小齿轮上有一个小人——那就是我们自己。我们只看到这个小人毫无规律的在幕布前表演，却无法预测他下一步会去哪。而幕布后面的齿轮却永远一直那样不停的旋转，永不停歇。</p>
</blockquote>
<p>如何用一幅图总结频域、时域、相位谱的关系(引自<a href="https://zhuanlan.zhihu.com/p/19763358?from=singlemessage&amp;isappinstalled=1" target="_blank" rel="noopener">知乎</a>)<br><img src="/img/ft3.jpeg" width="500" alt="图片名称" align="center"></p>
<h3 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h3><p>以音频文件采样为例：同图像bmp文件一样，pcm文件保存的是未压缩的音频信息。<br>16bits 编码是指，每次采样的音频信息用2个字节保存。可以对比下bmp文件用分别用2个字节保存RGB颜色的信息。<br>16000采样率 是指 1秒钟采样 16000次。当前声卡常用的采样频率一般为44.1KHz，即一秒采样44100次，人耳最敏感的听力范围20Hz到8000Hz。显然采样频率越高声音的还原就越真实越自然。<br>即：1秒的16000采样率音频文件大小是 $2\times16000 = 32000$字节 ，约为32K<br><strong>采样定理：衡量的是采样频率与信号频率之间的关系。采样定理规定，采样频率必须大于等于信号频率的两倍，才能够将原始信号从采样定理中完全恢复出来，否则会造成频率曲线混叠</strong></p>
<h3 id="图像大小变换"><a href="#图像大小变换" class="headerlink" title="图像大小变换"></a>图像大小变换</h3><p>图像像素数量 = 图像分辨率相乘，例如：图像分辨率为$1280\times720$，那么这张图片像素有100万。在同一台设备上，图片分辨率越高，这张图片1:1放大时，图片面积越大；图片分辨率越低，这张图片1:1缩放时，图片面积越小。<br>所以，将$1280 \times720 $的图像缩小到$720 \times 540$时，便需要采用下采样，这样再在同一台设备上，处理后的图片size就比较小。python代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">filename = <span class="string">"/Users/wxj/Desktop/WechatIMG2.jpeg"</span></span><br><span class="line">img = Image.open(filename)</span><br><span class="line">imgSize = img.size <span class="comment">#图片的长和宽</span></span><br><span class="line"><span class="keyword">print</span> (imgSize) <span class="comment"># 1920*1080</span></span><br><span class="line">out = img.resize((<span class="number">1080</span>，<span class="number">640</span>),Image.ANTIALIAS) <span class="comment">#降低分辨率</span></span><br><span class="line">out.save(<span class="string">"1.jpg"</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="图像尺寸怎么计算呢？"><a href="#图像尺寸怎么计算呢？" class="headerlink" title="图像尺寸怎么计算呢？"></a>图像尺寸怎么计算呢？</h4><p>pic_size = 分辨率$\times$3字节(rgb)图像，但这样发现跟电脑中显示的大小不同，因为图像文件(.jpg、png)等，都是有损压缩，一般会压缩几十到几百倍不等这样子。</p>
<h4 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a>图像金字塔</h4><p>图像金字塔算法是对图像的下采样、上采样：</p>
<blockquote>
<ul>
<li>其中下采样为采用高斯内核卷积；之后去除偶数行列</li>
<li>上采样为将图像在每个方向扩大为原来的两倍，新增的行和列以0填充；再使用先前同样的内核(乘以4)与放大后的图像卷积，获得 “新增像素”的近似值<br>而resize函数改变大小与图像金字塔的不同，采用的是线性插值补全丢失的像素，但实际用下来差别不大。</li>
</ul>
</blockquote>
<p>&nbsp;<br>插个话：图像金字塔在目标检测中的应用<br>滑窗的尺寸一般是固定的，而多尺度通过图像金字塔实现。这样相比不断改变滑窗大小，效率更高。至于缩小多少倍，源图缩到滑动窗口大小即可以，这样代表整张图片是某个类。</p>
<p>假如人脸size[20,20]，滑动窗口（box）Size[40,40]那么可能检不出这张人脸（人脸占据比例太小），而随着图像金字塔变换人脸size会越来越小，那人脸占据整个box的比例也会更低，导致无法检出。<br>换句话说：MinFaceSize(40)，只能检测最小约为[40，40]的人脸。</p>
<h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref:"></a>Ref:</h3><p><a href="https://zhuanlan.zhihu.com/p/19763358?from=singlemessage&amp;isappinstalled=1" target="_blank" rel="noopener">傅里叶分析之掐死教程（完整版）更新于2014.06.06</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://ws1.sinaimg.cn/large/006tNc79ly1fnu0obfmlbj30sg0iyabk.jpg"
                alt="祥吉" />
            
              <p class="site-author-name" itemprop="name">祥吉</p>
              <p class="site-description motion-element" itemprop="description">NLP/CV，Studying，Coding</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:wuxj231@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/xj-wu-74/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-rocket"></i>知乎</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/5379129372/home?wvr=5&lf=reg" target="_blank" title="微博">
                      
                        <i class="fa fa-fw fa-weibo"></i>微博</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">祥吉</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>


              
 
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共26.7k字</span>
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  


















  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  
</body>
</html>
